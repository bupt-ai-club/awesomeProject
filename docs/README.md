# Awesome Project

随着大模型的兴起，各类AI项目层出不穷，本项目以人工智能领域知识共享为目的，收集一些高质量的开源AI项目，帮助更多人了解相关东西，并且每周会在公众号做一次汇总和分享，而且在后续有时间的时候会对汇总的项目做一些实践和解读，同时也欢迎感兴趣的同学一起加入~

## 公众号（WeChat Official Account）

![QR](contents/QR.png)

## 专题（Special Topic）

- [科研工具专题](contents/20231225-20231231/20231225-20231231.md)


## 汇总(Summary)
| Name  | description | Tag| Source |
| ---- |  ---- | ---- |---- |
| [Prompt Engineering Guide](https://www.promptingguide.ai/zh) |提示工程指南（Prompt Engineering Guide）是由 DAIR.AI 发起的项目，分别从提示工程简介、提示技术、提示应用、模型、风险和误用、论文、工具和库等方面来帮助用户更好地了解大型语言模型的能力和局限性。  |LLM |[Awesome Project第2期](contents/20231030-20231105/20231030-20231105.md) |
| [prompt-engineering-for-developers](https://datawhalechina.github.io/prompt-engineering-for-developers/) |本项目是一个面向开发者的 LLM 入门教程，由Datawhale组织基于吴恩达老师大模型系列课程内容，将原课程内容翻译为中文并复现其范例代码，实现中文 Prompt，指导国内开发者如何基于 LLM 快速、高效开发具备强大能力的应用程序。  |LLM |[Awesome Project第2期](contents/20231030-20231105/20231030-20231105.md) |
| [Llama2 入门指南](https://ai.meta.com/llama/get-started) |官方的Llama 2教程，首先介绍了Llama 2的快速设置和操作指南，包括先决条件、获取模型和托管。然后，详细介绍了如何微调、量化、提示和推理Llama 2。接着提供了集成指南，包括Code Llama、LangChain和LlamaIndex。最后，文章讨论了社区支持和资源，以及如何提交反馈和建议。  |LLM |[Awesome Project第2期](contents/20231030-20231105/20231030-20231105.md) |
| [![Star](https://img.shields.io/github/stars/alextamkin/generative-elicitation.svg?style=social&label=Star)](https://github.com/alextamkin/generative-elicitation)<br> [GATE](https://github.com/alextamkin/generative-elicitation) |麻省理工学院研究人员开发出一种GATE框架,解决用户不会LLMs提示词的问题,GATE会主动地与你进行开放式的对话，通过一些列对话了解你的需求和偏好。了解用户的需求后，GATE就会生成适当的Prompt，然后传给LLMs。这样模型就能更准确地生成符合你需求的答案。  |LLM |[Awesome Project第2期](contents/20231030-20231105/20231030-20231105.md) |
| [![Star](https://img.shields.io/github/stars/ninehills/langeval.svg?style=social&label=Star)](https://github.com/ninehills/langeval)<br> [Langeval](https://github.com/ninehills/langeval) |开源 langeval 框架，核心功能是给大模型Prompt以及App做评估。  |LLM |[Awesome Project第2期](contents/20231030-20231105/20231030-20231105.md) |
| [![Star](https://img.shields.io/github/stars/WooooDyy/LLM-Agent-Paper-List.svg?style=social&label=Star)](https://github.com/WooooDyy/LLM-Agent-Paper-List)<br> [LLM-Agent-Paper-List](https://github.com/WooooDyy/LLM-Agent-Paper-List) |The Rise and Potential of Large Language Model Based Agents: A Survey 的paper 列表，对基于 LLM 的Agent进行了系统且全面的调查，并列出了一些必读论文。  |LLM |[Awesome Project第2期](contents/20231030-20231105/20231030-20231105.md) |
| [![Star](https://img.shields.io/github/stars/BerriAI/litellm.svg?style=social&label=Star)](https://github.com/BerriAI/litellm)<br> [Litellm](https://github.com/BerriAI/litellm) |使用 OpenAI 格式调用所有 LLM API [Bedrock、Huggingface、Cohere、TogetherAI、Azure、OpenAI 等]  |LLM |[Awesome Project第2期](contents/20231030-20231105/20231030-20231105.md) |
| [![Star](https://img.shields.io/github/stars/GPT-Fathom/GPT-Fathom.svg?style=social&label=Star)](https://github.com/GPT-Fathom/GPT-Fathom)<br> [GPT-Fathom](https://github.com/GPT-Fathom/GPT-Fathom) |GPT-Fathom 是由字节开源且可重复的 LLM 评估套件，在一致的设置下对 10 多个领先的开源和闭源 LLM 以及 OpenAI 的早期模型进行了 20 多个策划基准的基准测试。包括添加代码数据是否能提高LLM的推理能力、LLM能力的哪些方面可以通过SFT和RLHF提高、对齐程度等技术细节，分析并揭示了其中许多问题，旨在提高LLM的透明度。  |LLM |[Awesome Project第2期](contents/20231030-20231105/20231030-20231105.md) |
| [![Star](https://img.shields.io/github/stars/OpenTalker/video-retalking.svg?style=social&label=Star)](https://github.com/OpenTalker/video-retalking)<br> [VideoReTalking 让视频中的人物随意【对嘴型】](https://github.com/OpenTalker/video-retalking) |提出了一种名为VideoReTalking的音频驱动的唇同步技术，用于在现实世界中编辑说话者视频。VideoReTalking通过使用音频信号来驱动视频中的唇部运动，从而实现高质量的唇同步。这种方法可以应用于各种场景，如电影、广告、新闻等，以提高视频的观看体验。VideoReTalking算法的主要实现步骤：  |音频 |[Awesome Project第2期](contents/20231030-20231105/20231030-20231105.md) |
| [![Star](https://img.shields.io/github/stars/microsoft/generative-ai-for-beginners.svg?style=social&label=Star)](https://github.com/microsoft/generative-ai-for-beginners)<br> [VideoReTalking 让视频中的人物随意【对嘴型】](https://github.com/microsoft/generative-ai-for-beginners) |微软推出的专门针对初学者的生成式人工智能课程，通过 Microsoft Cloud Advocates 提供的 12 课时综合课程，了解构建生成式 AI 应用程序的基础知识。12 课时的课程，旨在教授初学者如何开始构建生成式AI应用。每节课都涵盖了生成式AI原理和应用开发的关键方面。在这个课程的学习过程中，学员不仅仅是学习理论知识，而是会实际操作，模拟创建一个使用生成式AI技术的创业公司。  |生成式AI |[Awesome Project第2期](contents/20231030-20231105/20231030-20231105.md) |
| [![Star](https://img.shields.io/github/stars/jack-willturner/deep-compression.svg?style=social&label=Star)](https://github.com/jack-willturner/deep-compression)<br> [deep-compression](https://github.com/jack-willturner/deep-compression) |对论文Learning both Weights and Connections for Efficient Neural Networks的代码复现，该论文主要研究了如何同时学习神经网络的权重和连接，以提高神经网络的效率。论文首先介绍了神经网络的基本结构和训练方法，然后提出了一种新的方法，即同时学习权重和连接。这种方法可以有效地减少神经网络的参数数量，从而提高计算效率。同时，这种方法还可以提高神经网络的泛化能力，使其在面对新的数据时能够更好地进行预测。论文还对这种方法进行了详细的实验验证，并与其他常见的神经网络训练方法进行了比较。实验结果表明，这种方法在保持预测精度的同时，可以显著减少神经网络的参数数量，从而提高计算效率。总的来说，这篇论文提出了一种新的方法，可以同时学习神经网络的权重和连接，以提高神经网络的效率。这种方法在实际应用中具有很大的潜力，可以为神经网络的训练和应用带来新的突破。代码支持对resnet9, resnet18, resnet34, resnet50, wrn_40_2, wrn_16_2, wrn_40_1等网络进行裁剪，适合入门学习！  |模型裁剪 |[Awesome Project第1期](contents/20231023-20231029/20231023-20231029.md) |
| [Efficient-Deep-Learning](https://dlsyscourse.org/lectures/) |具体来说，课程囊括了深度学习系统的“全栈”开发：从现代深度学习系统的高级建模设计，到自动微分工具的基本实现，再到底层高效算法的设备级实现……它将全部涉及。通过这门课，你将学会从头开始设计和构建一个完整的深度学习库。该库能够实现基于GPU的高效操作，自动区分所有实现的功能，并带有支持参数化层、损失函数、数据加载和优化器的必要模块。在自己开发的这个库之上，你可以构建几种SOTA模型，包括用于图像分类和分割的卷积网络、用于语言建模等连续任务的递归网络和自注意力模型，以及用于图像生成的生成模型等。  |深度学习课程 |[Awesome Project第1期](contents/20231023-20231029/20231023-20231029.md) |
| [awesome-llm](https://gitee.com/oschina/awesome-llm) |LLM 通常基于神经网络模型，使用大规模的语料库进行训练，比如使用互联网上的海量文本数据。这些模型通常拥有数十亿到数万亿个参数，能够处理各种自然语言处理任务，如自然语言生成、文本分类、文本摘要、机器翻译、语音识别等。本文对国内外公司、科研机构等组织开源的 LLM 进行了全面的整理,对开源中文 LLM、开源LLM、LLM相关工具都做了整理。  |LLM |[Awesome Project第1期](contents/20231023-20231029/20231023-20231029.md) |
| [llm-map](https://gitee.com/oschina/llm-map) |LLM 技术图谱（LLM Tech Map）是将 LLM 相关技术进行系统化和图形化的呈现，此图谱主要特点是“专注于技术人视角”，不求从 LLM 产业角度汇聚信息，而是希望让从事相关工作或是想了解 LLM 的技术人有一个快速感知。LLM 技术图谱（LLM Tech Map）从基础设施、大模型、Agent、AI 编程、工具和平台，以及算力几个方面，为开发者整理了当前 LLM 中最为热门和硬核的技术领域以及相关的软件产品和开源项目。  |LLM |[Awesome Project第1期](contents/20231023-20231029/20231023-20231029.md) |
| [llm-action](https://www.bilibili.com/video/BV1K8411y7Ei) |ComfyUI系统性教程，从AIGC浪潮聚焦到Diffusion Model的系统梳理，从理论的角度理解扩散模型如何实现0到1的跨越。通过通俗易懂的语言对SD的原理进行了解析。  |Stable Diffusion |[Awesome Project第1期](contents/20231023-20231029/20231023-20231029.md) |
| [llm-action](https://kimi.moonshot.cn/) |简直是科研神器！月之暗面由清华大学交叉信息学院、智源青年科学家杨植麟教授领衔，其在过去五年内的NLP领域华人学者引用排名中位居前10，并在40岁以下排名第一；两位联合创始人周昕宇和吴育昕，也均出身清华。团队还成功吸引了来自Google、Meta、Amazon等全球领先科技公司的海外人才加入。专注于通用人工智能领域的公司月之暗面（Moonshot Al）宣布在“长文本”领域实现了突破，推出了首个支持输入20万汉字的大模型moonshot，以及搭载该模型的智能助手产品Kimi Chat。  |工具 |[Awesome Project第1期](contents/20231023-20231029/20231023-20231029.md) |
| [Animatedai](https://animatedai.github.io/) |用动画代替方程，揭开人工智能和神经网络的神秘面纱。该网站使用以易于理解的动画方式解释了书面难以理解的广泛用于机器学习领域的“卷积神经网络（CNN）”  |深度学习 |[Awesome Project第3期](contents/20231106-20231112/20231106-20231112.md) |
| [![Star](https://img.shields.io/github/stars/HanXinzi-AI/awesome-python-machine-learning-resources.svg?style=social&label=Star)](https://github.com/HanXinzi-AI/awesome-python-machine-learning-resources)<br> [python机器学习资源与工具库大全](https://github.com/HanXinzi-AI/awesome-python-machine-learning-resources) |本资源清单包含python机器学习相关的开源工具资源，这些热门工具总共分成32个不同的子板块  |深度学习 |[Awesome Project第3期](contents/20231106-20231112/20231106-20231112.md) |
| [![Star](https://img.shields.io/github/stars/HanXinzi-AI/awesome-jupyter-resources.svg?style=social&label=Star)](https://github.com/HanXinzi-AI/awesome-jupyter-resources)<br> [Jupyter资源与工具库大全](https://github.com/HanXinzi-AI/awesome-jupyter-resources) |本资源清单包含jupyter相关的开源工具资源，这些热门工具总共分成13个不同的子板块  |深度学习 |[Awesome Project第3期](contents/20231106-20231112/20231106-20231112.md) |
| [![Star](https://img.shields.io/github/stars/HanXinzi-AI/awesome-NLP-resources.svg?style=social&label=Star)](https://github.com/HanXinzi-AI/awesome-NLP-resources)<br> [自然语言处理项目&工具库&资源大全](https://github.com/HanXinzi-AI/awesome-NLP-resources) |本资源清单包含100个python自然语言处理相关的项目&工具库&资源，这些资源总共分成11个不同的子板块  |深度学习 |[Awesome Project第3期](contents/20231106-20231112/20231106-20231112.md) |
| [![Star](https://img.shields.io/github/stars/HanXinzi-AI/awesome-computer-vision-resources.svg?style=social&label=Star)](https://github.com/HanXinzi-AI/awesome-computer-vision-resources)<br> [计算机视觉项目&工具库&资源大全](https://github.com/HanXinzi-AI/awesome-computer-vision-resources) |本资源清单包含120个计算机视觉相关的项目&工具库&资源，这些资源总共分成12个不同的子板块  |深度学习 |[Awesome Project第3期](contents/20231106-20231112/20231106-20231112.md) |
| [![Star](https://img.shields.io/github/stars/horseee/Awesome-Efficient-LLM.svg?style=social&label=Star)](https://github.com/horseee/Awesome-Efficient-LLM)<br> [Awesome Efficient LLM](https://github.com/horseee/Awesome-Efficient-LLM) |该项目收录了一些高效大型语言模型的精选列表  |Model Compression |[Awesome Project第3期](contents/20231106-20231112/20231106-20231112.md) |
| [![Star](https://img.shields.io/github/stars/e2b-dev/awesome-ai-agents.svg?style=social&label=Star)](https://github.com/e2b-dev/awesome-ai-agents)<br> [Awesome AI Agents](https://github.com/e2b-dev/awesome-ai-agents) |收录一些AI Agent相关的项目  |LLM |[Awesome Project第3期](contents/20231106-20231112/20231106-20231112.md) |
| [![Star](https://img.shields.io/github/stars/PKU-RL/LLaMA-Rider.svg?style=social&label=Star)](https://github.com/PKU-RL/LLaMA-Rider)<br> [LLaMA Rider](https://github.com/PKU-RL/LLaMA-Rider) |北京大学和北京智源人工智能研究院的团队提出的 LLaMA-Rider，赋予了大模型在开放世界中探索任务、收集数据、学习策略的能力，助力Agent在《我的世界》中自主探索获取知识并学习解决各种任务，提升Agent自主能力和通用性。  |LLM |[Awesome Project第3期](contents/20231106-20231112/20231106-20231112.md) |
| [GPTsHunter](https://www.gptshunter.com/) |该项目分享并发现 OpenAI GPT 商店中最好的自定义 GPT,截止目前，已收录了1767 GPTs。  |LLM |[Awesome Project第3期](contents/20231106-20231112/20231106-20231112.md) |
| [完蛋！我被 LLM 包围了！](https://modelscope.cn/studios/LLMRiddles/LLMRiddles/summary) |通过解谜游戏的方式轻松学会大模型提示词技巧，游戏共四章、19道题，玩家通过设计提示词，想方设法让模型输出指定答案。  |LLM |[Awesome Project第3期](contents/20231106-20231112/20231106-20231112.md) |
| [文本转语音](https://huggingface.co/spaces/ysharma/OpenAI_TTS_New) |基于 OpenAI 的 TTS 模型将文本转换为逼真的语音音频，并提供了一个名为speech的 API。支持多种语言，比如英语、西班牙语、法语、德语、意大利语等，此外，还支持 tts-1、tts-1-hd 和 tts-2等多种语音模型，并且可以在5 种男声和2种女声中进行切换。  |Tools |[Awesome Project第3期](contents/20231106-20231112/20231106-20231112.md) |
| [ChatGPT 正在产生心智吗](https://www.bilibili.com/video/BV1uu4y1m7ak) |通过通俗易懂的方式介绍了神经网络、Transformer、深度学习训练、涌现、幻觉、压缩、思维链等内容，适合小白入门，特效炸裂，推荐观看！  |Course |[Awesome Project第3期](contents/20231106-20231112/20231106-20231112.md) |
| [![Star](https://img.shields.io/github/stars/HanXinzi-AI/awesome-python-resources.svg?style=social&label=Star)](https://github.com/HanXinzi-AI/awesome-python-resources)<br> [Awesome-Python-Resources](https://github.com/HanXinzi-AI/awesome-python-resources) |本资源清单包含690个python相关的开源工具资源，这些热门工具总共分成91个不同的应用领域，  |其他 |[Awesome Project第3期](contents/20231106-20231112/20231106-20231112.md) |
| [Generative AI with Large Language Models](https://www.coursera.org/learn/generative-ai-with-llms) |由AWS 和 DeepMind 合作推出的大模型学习课程，本课程学习生成式 AI 工作原理以及如何将其部署到实际应用程序中的基础知识。课程难度为中级，适合具有一定 Python 编程经验的学员。主要包含生成式人工智能应用案例、项目生命周期和模型预训练、微调和评估大语言模型、强化学习和大语言模型驱动的应用等内容。  |Course |[Awesome Project第4期](contents/20231113-20231119/20231113-20231119.md) |
| [![Star](https://img.shields.io/github/stars/morsoli/llm-books.svg?style=social&label=Star)](https://github.com/morsoli/llm-books)<br> [LLM 应用开发实践笔记](https://github.com/morsoli/llm-books) |在学习开发基于大语言模型的应用过程中，总结出来的一些经验和方法以及接触到的一些资源，采用理论学习和代码实践相结合的形式。包含理论学习和代码实践两部分。其中，理论学习部分由Langchain、LlamaIndex等开源工具文档、一些最佳实践的技术博客、论文阅读三部分组成。代码实践部分，在每个工具的理论学习结束后，辅以实践性代码帮助理解。最后会将各个模块整合起来实现一个信息处理系统。  |Course |[Awesome Project第4期](contents/20231113-20231119/20231113-20231119.md) |
| [Generative AI Learning Path](https://cloudskillsboost.google/journeys/118) |Google推出的课程，本学习路径概述了生成式人工智能的概念，从大型语言模型的基本原理到负责任的人工智能原则。课程内容包括：解释什么是生成式 AI、它的用途以及与传统机器学习方法的区别；探讨什么是大型语言模型 (LLM)、适合的应用场景以及如何使用提示调整来提升 LLM 性能；解释什么是负责任的人工智能，为什么它很重要，以及Google如何在其产品中实施负责任的人工智能等  |Course |[Awesome Project第4期](contents/20231113-20231119/20231113-20231119.md) |
| [11-667: Large Language Models Methods and Application](https://cmu-llms.org) |大型语言模型方法和应用（11-667）是一门研究生课程，旨在提供大型语言模型当前状态的整体视图。本课程的前半部分从语言模型的基础开始，包括网络架构、训练、推理和评估。然后讨论大型语言模型的解释（或尝试）、对齐和新兴功能，然后讨论其在语言任务中的流行应用以及文本之外的新用途。在后半部分，本课程首先介绍扩大语言模型预训练的技术以及使大型模型的预训练及其部署更加高效的最新方法。然后讨论了围绕大型语言模型部署的各种问题，并总结了LLM发展的挑战和前沿。  |Course |[Awesome Project第4期](contents/20231113-20231119/20231113-20231119.md) |
| [![Star](https://img.shields.io/github/stars/all-in-aigc/gpts-works.svg?style=social&label=Star)](https://github.com/all-in-aigc/gpts-works)<br> [GPTs Works](https://github.com/all-in-aigc/gpts-works) |这是一个第三方的GPTs 商店，不仅仅可以用于做 GPTs 导航，还可以用来做通用导航站。此外，还集成了向量化处理，即用户可以用自然语言语义化来搜索，而不仅仅靠关键词匹配。最后支持以Chrome浏览器插件方式安装。  |Tools |[Awesome Project第4期](contents/20231113-20231119/20231113-20231119.md) |
| [![Star](https://img.shields.io/github/stars/lxfater/Awesome-GPTs.svg?style=social&label=Star)](https://github.com/lxfater/Awesome-GPTs)<br> [Awesome GPTs](https://github.com/lxfater/Awesome-GPTs) |列举了一些GPTs和一些有意思的Prompt。  |Tools |[Awesome Project第4期](contents/20231113-20231119/20231113-20231119.md) |
| [![Star](https://img.shields.io/github/stars/openchatai/OpenCopilot.svg?style=social&label=Star)](https://github.com/openchatai/OpenCopilot)<br> [OpenCopilot](https://github.com/openchatai/OpenCopilot) |OpenCopilot旨在成为用户自己的AI副驾驶，专门为他们的产品量身定制。与通用的AI解决方案不同，OpenCopilot与产品的底层API深度集成。凭借轻松执行 API 调用的主要功能，它是一种工具，可以显着提高效率并减少与 API 接口所涉及的手动工作。它的操作植根于使用大型语言模型 （LLM），该模型分析用户请求以确定 API 调用的必要性。在做出这样的决定后，OpenCopilot 会选择合适的 API 端点，并根据 API 定义发送所需的有效负载。  |Tools |[Awesome Project第4期](contents/20231113-20231119/20231113-20231119.md) |
| [![Star](https://img.shields.io/github/stars/netease-youdao/emotivoice.svg?style=social&label=Star)](https://github.com/netease-youdao/emotivoice)<br> [EmotiVoice易魔声 😊: 多音色提示控制TTS](https://github.com/netease-youdao/emotivoice) |EmotiVoice是一个强大的开源TTS引擎，支持中英文双语，包含2000多种不同的音色，以及特色的情感合成功能，支持合成包含快乐、兴奋、悲伤、愤怒等广泛情感的语音。EmotiVoice提供一个易于使用的web界面，还有用于批量生成结果的脚本接口。  |Tools |[Awesome Project第4期](contents/20231113-20231119/20231113-20231119.md) |
| [如何阅读一篇论文](https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf) |这篇文章主要介绍了一种名为“三遍阅读法”的高效阅读研究论文的方法。作者S. Keshav是加拿大滑铁卢大学计算机科学教授，他分享了自己的经验，帮助研究者更高效地阅读和理解论文。  |Course |[Awesome Project第5期](contents/20231120-20231126/20231120-20231126.md) |
| [Aminer](www.aminer.cn) |由清华大学计算机系研发的学术信息挖掘平台，可以很大程度帮助降低检索和学习论文的门槛。如果你有一个明确的研究方向，可以在它的「必读论文」模块中找到对应的优质论文集，这些内容都是由 AI 初筛 + 学者复核后呈现出来的，可以为自己省去海量的信息挖掘时间。  |Tools |[Awesome Project第5期](contents/20231120-20231126/20231120-20231126.md) |
| [GPTseek](https://gptseek.com) |发现优质的 GPTs。可以根据评分来排序，导航和分类都很清晰，可以查找相似 GPTs。  |Tools |[Awesome Project第5期](contents/20231120-20231126/20231120-20231126.md) |
| [Vectorart](https://vectorart.ai/) |根据文本生成SVG矢量图片，个人或者教育用途可以免费下载，商业用途需要付费。  |Tools |[Awesome Project第5期](contents/20231120-20231126/20231120-20231126.md) |
| [![Star](https://img.shields.io/github/stars/tldraw/draw-fast.svg?style=social&label=Star)](https://github.com/tldraw/draw-fast)<br> [Draw Fast](https://github.com/tldraw/draw-fast) |使用Latent Consistency Models将实时将草图渲染成真实的图片，  |Tools |[Awesome Project第5期](contents/20231120-20231126/20231120-20231126.md) |
| [![Star](https://img.shields.io/github/stars/pAIrprogio/vscode-ui-sketcher.svg?style=social&label=Star)](https://github.com/pAIrprogio/vscode-ui-sketcher)<br> [UI Sketcher](https://github.com/pAIrprogio/vscode-ui-sketcher) |是一个VSCode插件，依据GPT-4V的多模态能力，可以通过画出界面草图，就能生成一个基于ReactNative的UI界面。  |Tools |[Awesome Project第5期](contents/20231120-20231126/20231120-20231126.md) |
| [![Star](https://img.shields.io/github/stars/BloopAI/bloop.svg?style=social&label=Star)](https://github.com/BloopAI/bloop)<br> [bloop](https://github.com/BloopAI/bloop) |一个用 Rust 和 Typescript 编写的快速代码搜索引擎。同时它接入了GPT-4，使得可以直接使用自然语言来搜索，以及用自然语言来解释代码库是做什么的。同时支持正则表达式和过滤查询搜索本地和远程存储库。  |Tools |[Awesome Project第5期](contents/20231120-20231126/20231120-20231126.md) |
| [最懂程序员的新一代 AI 搜索引擎](https://devv.ai/) |Devv.ai 是一个专门为开发者设计的 AI 搜索引擎。它的目标是为编程领域提供比传统搜索引擎如 Google 或开发者社区如 StackOverflow 更精确和高效的答案。Devv.ai 的开发团队构建了一个高效且准确的系统，该系统基于文档、代码和实时搜索数据，并且使用了微调后的 Code Llama 和 GPT-3.5 模型。用户反馈显示，Devv.ai 的搜索结果比 GPT-4 更清晰，信息源质量也非常高，能够在很大程度上满足开发者在编程过程中的查询需求。  |Tools |[Awesome Project第6期](contents/20231127-20231203/20231127-20231203.md) |
| [公益学术平台PubScholar](https://pubscholar.cn/) |PubScholar公益学术平台是中国科学院作为国家战略科技力量的主力军，履行学术资源保障“国家队”职责，为满足全国科技界和全社会科技创新的学术资源基础保障需求，建设的提供公益性学术资源的检索发现、内容获取和交流共享等服务的平台。  |Tools |[Awesome Project第6期](contents/20231127-20231203/20231127-20231203.md) |
| [始智AI](https://www.wisemodel.cn) |始智AI，国内版的huggingface。目前的功能主要是提供开源模型和数据集下载、讨论。 ​​​  |Tools |[Awesome Project第6期](contents/20231127-20231203/20231127-20231203.md) |
| [![Star](https://img.shields.io/github/stars/VikParuchuri/marker.svg?style=social&label=Star)](https://github.com/VikParuchuri/marker)<br> [Marker](https://github.com/VikParuchuri/marker) |​​一个可以将 PDF、EPUB 和 MOBI 文件转换为 Markdown 的工具。工作原理是使用一系列深度学习模型来完成文本提取、布局检测、文本清理和格式化等任务。它在 GPU、CPU 或 MPS 上运行，以实现快速和准确的转换。它具有以下特点：  |Tools |[Awesome Project第6期](contents/20231127-20231203/20231127-20231203.md) |
| [![Star](https://img.shields.io/github/stars/srbhr/Resume-Matcher.svg?style=social&label=Star)](https://github.com/srbhr/Resume-Matcher)<br> [Resume Matcher](https://github.com/srbhr/Resume-Matcher) |帮助用户优化简历的开源工具。它通过使用语言模型来比较和排名简历与职位描述，从而帮助用户更好地定制简历以匹配目标职位。项目使用了 Python 进行解析，利用先进的机器学习算法提取关键词和主题，并使用 Qdrant 进行向量相似度计算。​​​  |Tools |[Awesome Project第6期](contents/20231127-20231203/20231127-20231203.md) |
| [![Star](https://img.shields.io/github/stars/facebookresearch/seamless_communication.svg?style=social&label=Star)](https://github.com/facebookresearch/seamless_communication)<br> [实时语音翻译模型 Seamless](https://github.com/facebookresearch/seamless_communication) |Meta 新推出的实时语音翻译模型 Seamless，能保持原声的表情和风格。能判断当前的上下文是否足够输出，如果还不足以判断语音的真实含义，会等待有足够输入后再输出。在语音生成文本和语音翻译方面超越了 Whisper 和 AudioPalm 2。  |语音 |[Awesome Project第6期](contents/20231127-20231203/20231127-20231203.md) |
| [![Star](https://img.shields.io/github/stars/Vchitect/LaVie.svg?style=social&label=Star)](https://github.com/Vchitect/LaVie)<br> [LaVie(Text2Video Model)](https://github.com/Vchitect/LaVie) |LaVie旨在通过利用预训练的文本到图像（Text-to-Image，T2I）模型作为基础，学习生成高质量、视觉上逼真且时间上连贯的视频，同时保持预训练T2I模型的强大创造性。  |多模态 |[Awesome Project第6期](contents/20231127-20231203/20231127-20231203.md) |
| [![Star](https://img.shields.io/github/stars/Vchitect/SEINE.svg?style=social&label=Star)](https://github.com/Vchitect/SEINE)<br> [SEINE(Image2Video  Model)](https://github.com/Vchitect/SEINE) |这篇论文提出了SEINE，一个短到长视频扩散模型，用于生成过渡和预测。SEINE是一个基于扩散模型的视频生成模型，旨在解决从短输入视频中生成长输出视频的挑战。为了实现这一目标，SEINE采用了一种两阶段的训练策略，首先学习从短输入视频中捕捉潜在表示，然后在这些表示的基础上生成长视频。  |多模态 |[Awesome Project第6期](contents/20231127-20231203/20231127-20231203.md) |
| [AI教程](https://space.bilibili.com/3129054/channel/collectiondetail?sid=874339) |​​​ OpenAI 大神 Andrej Karpathy 录制的AI相关课程视频，主要包括神经网络和反向传播构建、语言建模的详细介绍、在代码中构建GPT、大语音模型介绍等等。  |Course |[Awesome Project第7期](contents/20231204-20231210/20231204-20231210.md) |
| [ICML2023_Tutorial on Multimodal Machine Learning](https://space.bilibili.com/3129054/channel/collectiondetail?sid=874339) |​CMU 两位学者在 ICML 2023 的分享，主要内容是​多模态机器学习的基础知识和前沿进展。包含多模态的定义、多模态的核心技术挑战、表示 (Representation) 的子挑战、对齐 (Alignment) 的子挑战、未来的研究方向 (Future Directions)等。  |Course |[Awesome Project第7期](contents/20231204-20231210/20231204-20231210.md) |
| [发现最新最佳AI产品](https://top.aibase.com/) |​​AI产品聚合网站，包含了10064+个最佳人工智能产品和服务，每日持续更新，覆盖图像处理、视频创作、效率助手、写作灵感、艺术灵感、趣味、开发编程、聊天机器人、医疗健康、翻译等多个领域。  |Tools |[Awesome Project第7期](contents/20231204-20231210/20231204-20231210.md) |
| [![Star](https://img.shields.io/github/stars/LiLittleCat/awesome-free-chatgpt.svg?style=social&label=Star)](https://github.com/LiLittleCat/awesome-free-chatgpt)<br> [Awesome Free ChatGPT](https://github.com/LiLittleCat/awesome-free-chatgpt) |该项目收录了免费的 ChatGPT 镜像网站列表，目前已收录了200多个平替网站。  |Tools |[Awesome Project第7期](contents/20231204-20231210/20231204-20231210.md) |
| [![Star](https://img.shields.io/github/stars/km1994/LLMsNineStoryDemonTower.svg?style=social&label=Star)](https://github.com/km1994/LLMsNineStoryDemonTower)<br> [LLMs九层妖塔](https://github.com/km1994/LLMsNineStoryDemonTower) |​该项目分享 LLMs在自然语言处理（ChatGLM、Chinese-LLaMA-Alpaca、小羊驼 Vicuna、LLaMA、GPT4ALL等）、信息检索（langchain）、语言合成、语言识别、多模态等领域（Stable Diffusion、MiniGPT-4、VisualGLM-6B、Ziya-Visual等）等 实战与经验。  |LLM |[Awesome Project第7期](contents/20231204-20231210/20231204-20231210.md) |
| [LLM大模型训练专栏](https://www.zhihu.com/column/c_1252604770952642560) |​​该项目提供了一系列LLM前言理论和实战实验，包括论文解读与洞察分析。  |LLM |[Awesome Project第7期](contents/20231204-20231210/20231204-20231210.md) |
| [![Star](https://img.shields.io/github/stars/luban-agi/Awesome-Domain-LLM.svg?style=social&label=Star)](https://github.com/luban-agi/Awesome-Domain-LLM)<br> [Awesome-Domain-LLM](https://github.com/luban-agi/Awesome-Domain-LLM) |​该项目收集和梳理垂直领域的开源模型、数据集及评测基准。  |LLM |[Awesome Project第7期](contents/20231204-20231210/20231204-20231210.md) |
| [![Star](https://img.shields.io/github/stars/DSXiangLi/DecryptPrompt.svg?style=social&label=Star)](https://github.com/DSXiangLi/DecryptPrompt)<br> [DecryptPrompt](https://github.com/DSXiangLi/DecryptPrompt) |该项目​​总结了Prompt&LLM论文，开源数据&模型，AIGC应用。内容包括但不限于：提示工程（prompt engineering）、零/少样本学习、思维链（chain of thought）、模型训练、评估、可靠性优化、知识编辑等方面的研究和应用。  |LLM |[Awesome Project第7期](contents/20231204-20231210/20231204-20231210.md) |
| [![Star](https://img.shields.io/github/stars/lonePatient/awesome-pretrained-chinese-nlp-models.svg?style=social&label=Star)](https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models)<br> [Awesome Pretrained Chinese NLP Models](https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models) |在自然语言处理领域中，预训练语言模型（Pretrained Language Models）已成为非常重要的基础技术，本仓库主要收集目前网上公开的一些高质量中文预训练模型、中文多模态模型、中文大语言模型等内容  |LLM |[Awesome Project第7期](contents/20231204-20231210/20231204-20231210.md) |
| [![Star](https://img.shields.io/github/stars/DAMO-NLP-SG/LLM-Zoo.svg?style=social&label=Star)](https://github.com/DAMO-NLP-SG/LLM-Zoo)<br> [LLM-Zoo](https://github.com/DAMO-NLP-SG/LLM-Zoo) |​​​ 该项目收集了包括开源和闭源的LLM模型，具体包括了发布时间，模型大小，支持的语种，领域，训练数据及相应论文/仓库等。  |LLM |[Awesome Project第8期](contents/20231211-20231217/20231211-20231217.md) |
| [![Star](https://img.shields.io/github/stars/linexjlin/GPTs.svg?style=social&label=Star)](https://github.com/linexjlin/GPTs)<br> [GPTs](https://github.com/linexjlin/GPTs) |该仓库收集了泄露的 GPT 提示。  |LLM |[Awesome Project第8期](contents/20231211-20231217/20231211-20231217.md) |
| [![Star](https://img.shields.io/github/stars/sail-sg/CLoT.svg?style=social&label=Star)](https://github.com/sail-sg/CLoT)<br> [CLoT](https://github.com/sail-sg/CLoT) |探讨了如何提高大型语言模型（LLMs）在创意任务中的“跳跃思维”（Leap-of-Thought, LoT）能力。提出了创造性跳跃思维（Creative LoT, CLoT）框架，包括可关联指令调优阶段和探索性自精化阶段。前者将Oogiri-GO数据集转化为指令调优数据，以提升LLM的LoT能力；后者则让LLM在弱关联条件下生成更多创意LoT数据，并通过筛选高质量数据进行自精化。  |LLM |[Awesome Project第8期](contents/20231211-20231217/20231211-20231217.md) |
| [![Star](https://img.shields.io/github/stars/Ucas-HaoranWei/Vary.svg?style=social&label=Star)](https://github.com/Ucas-HaoranWei/Vary)<br> [Vary](https://github.com/Ucas-HaoranWei/Vary) |一套视觉感知上限极高的通用多模态框架,Vary充分探索了视觉词表对感知能力的影响，提供了一套有效的视觉词表扩充方法。通过在公开数据集以及我们渲染的文档图表数据上训练，在保持vanilla多模态能力的同时，还激发出了端到端的中英文图片、公式截图和图表理解能力。  |多模态 |[Awesome Project第8期](contents/20231211-20231217/20231211-20231217.md) |
| [![Star](https://img.shields.io/github/stars/Mintplex-Labs/anything-llm.svg?style=social&label=Star)](https://github.com/Mintplex-Labs/anything-llm)<br> [AnythingLLM](https://github.com/Mintplex-Labs/anything-llm) |可以与任何内容聊天的私人 ChatGPT，提供高效、可定制、开源的企业级文档聊天机器人解决方案。AnythingLLM 是一个全栈应用程序，可以使用商业现成的 LLM 或流行的开源 LLM 和 vectorDB 解决方案来构建私有 ChatGPT，可以在本地运行，也可以远程托管并能够智能聊天以及您提供的任何文件,支持无限的文档、线程、并发用户和管理。  |TOOLs |[Awesome Project第8期](contents/20231211-20231217/20231211-20231217.md) |
| [CS183B 怎样创立一家创业公司](http://startupclass.samaltman.com) |斯坦福大学开设的创业课程，讲师群星云集，包含OpenAI创始人Sam Altman，还有 PayPal 创始人 Peter Thiel，Pinterest 创始人 Ben Silbermann，以及著名投资人 Marc Andreessen、Ron Conway，课程内容包含如何积累初期用户、失败者才谈竞争、没有留存率不要谈推广、与你的用户谈恋爱等等。  |课程 |[Awesome Project第8期](contents/20231211-20231217/20231211-20231217.md) |
| [LLM训练指南llm-training](https://rentry.co/llm-training) |该项目是一个面向新手的训练LLM指南，系统地讲解了如何使用 Transformers 库和 Transformer 网络架构训练大型语言模型 (LLM)。教程内容包括本地微调、低秩适应(LoRA)、QLoRA、训练超参数、解读学习曲线等内容。  |课程 |[Awesome Project第8期](contents/20231211-20231217/20231211-20231217.md) |
| [![Star](https://img.shields.io/github/stars/lxfater/inpaint-web.svg?style=social&label=Star)](https://github.com/lxfater/inpaint-web)<br> [AI图片处理神器inpaint-web](https://github.com/lxfater/inpaint-web) |​​​ 基于 Webgpu 技术和 wasm 技术的免费开源 inpainting & image-upscaling 工具, 纯浏览器端实现。不仅能快速去水印，还能将模糊的图片变成高分辨率清晰图片。  |Tools |[Awesome Project第9期](contents/20231218-20231224/20231218-20231224.md) |
| [Zotero插件](https://zotero-chinese.com/) |​​Zotero Chinese主要维护一些与 Zotero 有关的中文文档、资料以及程序，提供很多好用的zotero插件。  |Tools |[Awesome Project第9期](contents/20231218-20231224/20231218-20231224.md) |
| [RAG 综述](https://arxiv.org/abs/2312.10997) |​​​这篇文章主要讨论了检索增强生成（RAG）的技术。RAG是一种结合了检索和生成的方法，它通过从大量的知识库中检索相关信息，然后用这些信息来生成回答，  |LLM |[Awesome Project第9期](contents/20231218-20231224/20231218-20231224.md) |
| [![Star](https://img.shields.io/github/stars/krishnaik06/Roadmap-To-Learn-Generative-AI-In-2024.svg?style=social&label=Star)](https://github.com/krishnaik06/Roadmap-To-Learn-Generative-AI-In-2024)<br> [2024 年学习生成式 AI 路线图](https://github.com/krishnaik06/Roadmap-To-Learn-Generative-AI-In-2024) |​​​介绍了生成式AI的学习路线。主要分为Python编程基础、机器学习自然语言处理基础、基础深度学习概念、高级NLP概念、  |Course |[Awesome Project第9期](contents/20231218-20231224/20231218-20231224.md) |
| [![Star](https://img.shields.io/github/stars/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming.svg?style=social&label=Star)](https://github.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming)<br> [学会与 GitHub Copilot 进行 AI 结对编程](https://github.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming) |​​​这是一个 6 课时的课程，教授有关利用 GitHub Copilot 和 AI 配对编程资源所需了解的所有信息。主要包括GitHub 简介、GitHub Copilot 简介、使用 GitHub Copilot 与 JavaScript、  |Course |[Awesome Project第9期](contents/20231218-20231224/20231218-20231224.md) |
| [Big ideas in tech in 2024](https://gamma.app/public/Big-Ideas-in-tech-in-2024-by-A16Z-phquomraxnzc1fs?mode=doc) |这个网站是关于Andreessen Horowitz（A16Z）发布的2024年科技大趋势的报告。报告中列出了A16Z认为将在2024年影响科技行业的一些重要趋势和创新。这些趋势涵盖了多个领域，  |其他 |[Awesome Project第9期](contents/20231218-20231224/20231218-20231224.md) |
| [用 RAGAs（检索增强生成评估）评估 RAG（检索增强型生成）应用 [译]](https://baoyu.io/translations/rag/evaluating-rag-applications-with-ragas?continueFlag=5d10d34c97637bebcfeba6470c0f0d9b) |​​​RAGAs框架提供了一种无需参照标准的评估方法，主要依赖于大语言模型（LLM）来评估RAG应用的组件和整体性能。文章详细解释了如何准备评估数据和使用RAGAs工具进行评估，并讨论了评估结果的解读。  |其他 |[Awesome Project第9期](contents/20231218-20231224/20231218-20231224.md) |
| [![Star](https://img.shields.io/github/stars/tatsu-lab/stanford_alpaca.svg?style=social&label=Star)](https://github.com/tatsu-lab/stanford_alpaca)<br> [Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca) |​​​ 用于训练斯坦福大学Alpaca模型并生成数据的代码和文档。Alpaca模型是一种大型语言模型，专注于提供更高效的文本生成和处理能力。项目旨在促进语言模型的研究与开发。  |LLM |[Awesome Project第11期](contents/20240101-20240106/20240101-20240106.md) |
| [![Star](https://img.shields.io/github/stars/openlm-research/open_llama.svg?style=social&label=Star)](https://github.com/openlm-research/open_llama)<br> [OpenLLaMA](https://github.com/openlm-research/open_llama) |​​​ OpenLLaMA是Meta AI的LLaMA 7B的一个开源复现项目，使用RedPajama数据集进行训练。提供一个与LLaMA 7B模型相似的开源版本，提供预训练 OpenLLaMA 模型的 PyTorch 和 JAX 权重，以及评估结果以及与原始 LLaMA 模型的比较。  |LLM |[Awesome Project第11期](contents/20240101-20240106/20240101-20240106.md) |
| [![Star](https://img.shields.io/github/stars/microsoft/autogen.svg?style=social&label=Star)](https://github.com/microsoft/autogen)<br> [AutoGen](https://github.com/microsoft/autogen) |​​​ AutoGen是由微软开发的基于多智能体的大规模语言模型应用开发框架，提供了一套工具和框架以简化和加速基于大型语言模型的应用开发和部署。  |LLM |[Awesome Project第11期](contents/20240101-20240106/20240101-20240106.md) |
| [![Star](https://img.shields.io/github/stars/Mooler0410/LLMsPracticalGuide.svg?style=social&label=Star)](https://github.com/Mooler0410/LLMsPracticalGuide)<br> [大型语言模型实用指南](https://github.com/Mooler0410/LLMsPracticalGuide) |​​​ LLMs Practical Guide是一个精心整理的大型语言模型(LLM)实用指南资源列表，包括LLM Tree、示例和论文。这个项目旨在为研究者和开发者提供关于大型语言模型的实践资源，比如使用方法、最佳实践和相关研究论文，助力于理解和运用大型语言模型。  |LLM |[Awesome Project第11期](contents/20240101-20240106/20240101-20240106.md) |
| [![Star](https://img.shields.io/github/stars/BradyFU/Awesome-Multimodal-Large-Language-Models.svg?style=social&label=Star)](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)<br> [Awesome Multimodal Large Language Models](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models) |​​​ 汇集了关于多模态大型语言模型的最新论文和数据集，以及它们的评估方法。  |多模态 |[Awesome Project第11期](contents/20240101-20240106/20240101-20240106.md) |
| [![Star](https://img.shields.io/github/stars/ConnectAI-E/Awesome-One-Click-Deployment.svg?style=social&label=Star)](https://github.com/ConnectAI-E/Awesome-One-Click-Deployment)<br> [一键部署大模型](https://github.com/ConnectAI-E/Awesome-One-Click-Deployment) |​​​ 一键部署各种Github开源AI项目，只需要在界面上点点点，专属于自己的AI应用就部署完成了，真的是有手就行。目前支持GeminiProChat、AutoGPT-Next-Web、wechat-chatgpt、chatbot-ui等项目，如图所示，可以创建一个自己的 Gemini Pro 大模型，无需额外服务器。  |工具 |[Awesome Project第11期](contents/20240101-20240106/20240101-20240106.md) |
| [![Star](https://img.shields.io/github/stars/microsoft/JARVIS.svg?style=social&label=Star)](https://github.com/microsoft/JARVIS)<br> [JARVIS](https://github.com/microsoft/JARVIS) |​​​ 一个将LLM与机器学习社区联系起来的系统。JARVIS 的使命是探索通用人工智能 (AGI) 并向整个社区提供前沿研究成果,介绍了如何利用大型语言模型来提升机器学习任务的性能和效率。  |工具 |[Awesome Project第11期](contents/20240101-20240106/20240101-20240106.md) |
| [![Star](https://img.shields.io/github/stars/ronreiter/interactive-tutorials?tab=readme-ov-file.svg?style=social&label=Star)](https://github.com/ronreiter/interactive-tutorials?tab=readme-ov-file)<br> [在线交互式教学工具](https://github.com/ronreiter/interactive-tutorials?tab=readme-ov-file) |​​​ 帮助你学习各类编程语言的在线交互式教学工具，背后使用的是 Sphere Engine，支持直接编译和运行各类语言代码，省却了本地安装环境的麻烦。目前支持的语言有Python、Java、Html、C、CPP、JS、PHP、Shell、C#、Perl、Ruby、Golang、Rust等。  |工具 |[Awesome Project第11期](contents/20240101-20240106/20240101-20240106.md) |
| [![Star](https://img.shields.io/github/stars/mlabonne/llm-course.svg?style=social&label=Star)](https://github.com/mlabonne/llm-course)<br> [大模型课程llm-course](https://github.com/mlabonne/llm-course) |​​​ LLM课程分为三个部分：（1）LLM 基础知识涵盖有关数学、Python 和神经网络的基本知识；（2）LLM科学家专注于学习如何使用最新技术建立最好的LLM；（3）LLM工程师专注于如何创建基于LLM的解决方案并部署它们。目前Github Star已达8K,强推！！！  |课程 |[Awesome Project第11期](contents/20240101-20240106/20240101-20240106.md) |
| [![Star](https://img.shields.io/github/stars/mlc-ai/mlc-llm.svg?style=social&label=Star)](https://github.com/mlc-ai/mlc-llm)<br> [mlc-llm](https://github.com/mlc-ai/mlc-llm) |​​​ 大型语言模型机器学习编译 (MLC LLM) 是一种高性能通用部署解决方案，允许使用具有编译器加速功能的本机 API 来本机部署任何大型语言模型。该项目的使命是让每个人都能够利用机器学习编译技术在每个人的设备上本地开发、优化和部署人工智能模型。  |LLM |[Awesome Project第12期](contents/20240107-20240113/20240107-20240113.md) |
| [![Star](https://img.shields.io/github/stars/huggingface/peft.svg?style=social&label=Star)](https://github.com/huggingface/peft)<br> [参数高效微调 PEFT](https://github.com/huggingface/peft) |​​​ 参数高效微调 (PEFT) 方法可以使预先训练的语言模型 (PLM) 有效适应各种下游应用程序，而无需微调所有模型的参数。微调大型 PLM 的成本往往高昂。在这方面，PEFT方法仅微调少量（额外）模型参数，从而大大降低了计算和存储成本。最近最先进的 PEFT 技术实现了与完全微调相当的性能。  |LLM |[Awesome Project第12期](contents/20240107-20240113/20240107-20240113.md) |
| [![Star](https://img.shields.io/github/stars/tloen/alpaca-lora.svg?style=social&label=Star)](https://github.com/tloen/alpaca-lora)<br> [Alpaca-LoRA](https://github.com/tloen/alpaca-lora) |​​​ 允许用户在消费级硬件上进行Instruct-tune LLaMA，即在不需要高端硬件的前提下，微调和优化LaMDA语言模型的项目。  |LLM |[Awesome Project第12期](contents/20240107-20240113/20240107-20240113.md) |
| [![Star](https://img.shields.io/github/stars/ray-project/llm-applications.svg?style=social&label=Star)](https://github.com/ray-project/llm-applications)<br> [手把手教你构建基于RAG的LLM应用](https://github.com/ray-project/llm-applications) |​​​ 介绍如何基于RAG (检索增强生成)构建 LLM 应用并将其部署到生产环境中。不仅有大量的结构示意图，还附上了实践代码，并且强调了开发过程中可能遇到的挑战以及解决方式，强推！！！  |LLM |[Awesome Project第12期](contents/20240107-20240113/20240107-20240113.md) |
| [![Star](https://img.shields.io/github/stars/peremartra/Large-Language-Model-Notebooks-Course.svg?style=social&label=Star)](https://github.com/peremartra/Large-Language-Model-Notebooks-Course)<br> [LLM课程](https://github.com/peremartra/Large-Language-Model-Notebooks-Course) |​​​ 本课程第一部分将学习如何使用大型语言模型世界中最常见的库，比如聊天机器人、代码生成、OpenAI API、Hugging Face、矢量数据库、LangChain、微调、PEFT 微调、软提示调优、LoRA、QLoRA、评估模型、知识蒸馏；第二部分将创建项目，解释设计决策，并将深入研究 LLMOps 相关主题；第三部分将探索如何构建能够改变拥有数千名员工的组织的解决方案，以及大型语言模型如何在这些新解决方案中发挥主要作用。  |课程 |[Awesome Project第12期](contents/20240107-20240113/20240107-20240113.md) |
| [CS479: Machine Learning for 3D Data](https://mhsung.github.io/kaist-cs479-fall-2023) |​​​ 3D 数据（深度传感器捕获的 3D 扫描和设计师创建的 3D 模型）广泛应用于计算机视觉、计算机图形学和机器人领域的许多应用，例如自动驾驶、AI 辅助 3D 对象/场景设计、增强现实、和物理机器人交互。随着最近对处理和分析此类 3D 数据的需求不断增加，新技术的开发取得了巨大进展，特别是基于深度学习的技术。在本课程中，我们将介绍 3D 数据机器学习技术的最新进展，并讨论剩余的挑战。  |课程 |[Awesome Project第12期](contents/20240107-20240113/20240107-20240113.md) |
| [![Star](https://img.shields.io/github/stars/adrianhajdin/docker-course.svg?style=social&label=Star)](https://github.com/adrianhajdin/docker-course)<br> [Docker 速成课程](https://github.com/adrianhajdin/docker-course) |​​​ 目前Docker已经成为开发人员的必备技能，该项目通过一门课程掌握 Docker；了解 Docker Hub 上的映像和容器、使用 Docker Compose 运行多个容器、使用 Docker Compose Watch 自动化工作流程等等。  |课程 |[Awesome Project第12期](contents/20240107-20240113/20240107-20240113.md) |
| [![Star](https://img.shields.io/github/stars/tyxsspa/AnyText.svg?style=social&label=Star)](https://github.com/tyxsspa/AnyText)<br> [AnyText](https://github.com/tyxsspa/AnyText) |​​​  AnyText 包含一个具有两个主要元素的扩散管道：辅助潜在模块和文本嵌入模块。前者使用文本字形、位置和蒙版图像等输入来生成用于文本生成或编辑的潜在特征。后者采用 OCR 模型将笔划数据编码为嵌入，与标记生成器中的图像标题嵌入混合，生成与背景无缝集成的文本。我们采用文本控制扩散损失和文本感知损失进行训练，以进一步提高书写准确性。 AnyText 可以用多种语言编写字符，这是第一个解决多语言视觉文本生成问题的工作。值得一提的是，AnyText 可以插入社区现有的扩散模型中，以准确地渲染或编辑文本。经过广泛的评估实验，我们的方法明显优于所有其他方法。此外，我们还贡献了第一个大规模多语言文本图像数据集 AnyWord-3M，其中包含 300 万个带有多种语言 OCR 注释的图像文本对。  |工具 |[Awesome Project第12期](contents/20240107-20240113/20240107-20240113.md) |
| [![Star](https://img.shields.io/github/stars/charent/ChatLM-mini-Chinese.svg?style=social&label=Star)](https://github.com/charent/ChatLM-mini-Chinese)<br> [ChatLM-mini-Chinese（0.2B）](https://github.com/charent/ChatLM-mini-Chinese) |​​​ 中文对话0.2B小模型（ChatLM-Chinese-0.2B），开源所有数据集来源、数据清洗、tokenizer训练、模型预训练、SFT指令微调、RLHF优化等流程的全部代码。支持下游任务sft微调。ChatLM-mini-Chinese为中文对话小模型，模型参数只有0.2B（算共享权重约210M），可以在最低4GB显存的机器进行预训练（batch_size=1，fp16或者 bf16），float16加载、推理最少只需要512MB显存。  |LLM |[Awesome Project第13期](contents/20240114-20240120/20240114-20240120.md) |
| [![Star](https://img.shields.io/github/stars/unit-mesh/unit-minions.svg?style=social&label=Star)](https://github.com/unit-mesh/unit-minions)<br> [AI 研发提效研究：自己动手训练 LoRA](https://github.com/unit-mesh/unit-minions) |​​​ 《AI 研发提效研究：自己动手训练 LoRA》，包含 Llama （Alpaca LoRA）模型、ChatGLM （ChatGLM Tuning）相关 Lora 的训练。训练内容：用户故事生成、测试代码生成、代码辅助生成、文本转 SQL、文本生成代码。包括了一些视频介绍、训练好的模型、训练代码、训练数据、训练过程中的一些记录。  |LLM |[Awesome Project第13期](contents/20240114-20240120/20240114-20240120.md) |
| [![Star](https://img.shields.io/github/stars/BaranziniLab/KG_RAG.svg?style=social&label=Star)](https://github.com/BaranziniLab/KG_RAG)<br> [KG_RAG](https://github.com/BaranziniLab/KG_RAG) |​​​ 使用基于知识图的检索增强生成 (KG-RAG) 为知识密集型任务赋能大型语言模型 (LLM)框架。该框架通过合并来自生物医学知识库的优化的特定领域“提示感知上下文”，支持通用LLM。  |LLM |[Awesome Project第13期](contents/20240114-20240120/20240114-20240120.md) |
| [![Star](https://img.shields.io/github/stars/hpcaitech/SwiftInfer.svg?style=social&label=Star)](https://github.com/hpcaitech/SwiftInfer)<br> [高效人工智能推理和服务SwiftInfer](https://github.com/hpcaitech/SwiftInfer) |​​Streaming-LLM 是一种支持无限输入长度进行 LLM 推理的技术。它利用注意力池来防止注意力窗口转移时模型崩溃。最初的工作是在 PyTorch 中实现的，我们提供 SwiftInfer，一个 TensorRT 实现，使 StreamingLLM 更具生产级。我们的实现基于最近发布的 TensorRT-LLM 项目。  |LLM |[Awesome Project第13期](contents/20240114-20240120/20240114-20240120.md) |
| [![Star](https://img.shields.io/github/stars/PKU-YuanGroup/Machine-Mindset.svg?style=social&label=Star)](https://github.com/PKU-YuanGroup/Machine-Mindset)<br> [MBTI大模型](https://github.com/PKU-YuanGroup/Machine-Mindset) |MM系列模型是由FarReel AI Lab与北大深研院合作开发的，这些模型结合了Baichuan和LLaMA2技术，并针对不同MBTI性格类型进行了优化。它们基于一个庞大的MBTI数据集（已开源），通过多阶段训练过程来提升性能，并计划不断更新以适应新任务。与使用提示改变模型性格的方法相比，这种方法更加稳定和有效。团队已成功创建了32个不同MBTI性格类型的模型，包括16个中文和16个英文版本。这是首次将性格心理学与大型语言模型结合的尝试，未来将继续探索个性化、情感陪伴和智能代理任务规划等领域。  |LLM |[Awesome Project第13期](contents/20240114-20240120/20240114-20240120.md) |
| [![Star](https://img.shields.io/github/stars/deepset-ai/haystack.svg?style=social&label=Star)](https://github.com/deepset-ai/haystack)<br> [Haystack](https://github.com/deepset-ai/haystack) |Haystack 是一个端到端 LLM 框架，使您能够构建由 LLMs、Transformer 模型、矢量搜索等支持的应用程序。无论您想要执行检索增强生成 (RAG)、文档搜索、问答还是答案生成，您都可以使用最先进的嵌入模型和 LLMs 与 Haystack 来构建端到端结束 NLP 应用程序来解决您的用例。强推！！！  |LLM |[Awesome Project第13期](contents/20240114-20240120/20240114-20240120.md) |
| [提示工程 Prompt Engineering 指南](https://realpython.com/practical-prompt-engineering/) |Real Python提供了一个关于“Prompt Engineering”的实用教程，通过一个实战项目带你走完开发全流程，旨在帮助开发者更好地利用大型语言模型（LLM）来完成特定的任务。教程详细介绍了如何通过精心设计的提示（prompts）来引导LLM产生期望的输出结果。  |AI教程 |[Awesome Project第13期](contents/20240114-20240120/20240114-20240120.md) |
| [![Star](https://img.shields.io/github/stars/tree/main.svg?style=social&label=Star)](https://github.com/tree/main)<br> [从头开始构建大型语言模型](https://github.com/rasbt/LLMs-from-scratch/tree/main) |从头开始构建大型语言模型，带你深入了解大语言模型的内容工作原理，一步步揭开 LLM 的神秘面纱，目前已开源前三章与书籍配套的全部代码！最后甚至可以在自己的笔记本上完成开发和部署，预计2025年出版，喜欢的朋友可以追更！  |AI教程 |[Awesome Project第13期](contents/20240114-20240120/20240114-20240120.md) |
| [![Star](https://img.shields.io/github/stars/dair-ai/ML-Papers-of-the-Week.svg?style=social&label=Star)](https://github.com/dair-ai/ML-Papers-of-the-Week)<br> [ML-Papers-of-the-Week](https://github.com/dair-ai/ML-Papers-of-the-Week) |​​​ 来自DAIR.AI团队，每周重点介绍顶级 ML 论文，推荐！！！  |深度学习 |[Awesome Project第14期](contents/20240122-20240128/20240122-20240128.md) |
| [![Star](https://img.shields.io/github/stars/inferflow/inferflow.svg?style=social&label=Star)](https://github.com/inferflow/inferflow)<br> [Inferflow](https://github.com/inferflow/inferflow) |​​​ Inferflow 是一种高效且高度可配置的大型语言模型推理引擎。使用Inferflow，用户只需修改相应配置文件中的一些行即可服务于大多数常见的Transformer模型，而无需编写一行源代码。Inferflow实现2位、3位、3.5位、4位、5位、6位和8位量化。在量化方案中，3.5位量化是Inferflow推出的新方案。支持多GPU推理，具有三种模型分区策略可供选择：按层分区（管道并行）、按张量分区（张量并行）和混合分区（混合并行）。其他推理引擎很少支持混合分区。支持三种类型的Transformer模型：仅解码器模型、仅编码器模型和编码器-解码器模型。  |LLM |[Awesome Project第14期](contents/20240122-20240128/20240122-20240128.md) |
| [![Star](https://img.shields.io/github/stars/UbiquitousLearning/Efficient_Foundation_Model_Survey.svg?style=social&label=Star)](https://github.com/UbiquitousLearning/Efficient_Foundation_Model_Survey)<br> [Efficient LLM and Multimodal Foundation Model Survey](https://github.com/UbiquitousLearning/Efficient_Foundation_Model_Survey) |​​​ 高效LLM和多模态基础模型相关论文资源列表，包括大型语言模型(LLM)、视觉Transformer(ViT)、扩散和LLM基础的多模态模型，它们如何在机器学习生命周期的各个阶段，从训练到部署。包含2020年以后发表的论文，范围为CS顶级会议上发表的论文，即CSRankings中收录的论文。此外，还从 arXiv 中手动挑选相关且可能具有高影响力的论文。  |LLM |[Awesome Project第14期](contents/20240122-20240128/20240122-20240128.md) |
| [![Star](https://img.shields.io/github/stars/huggingface/datatrove.svg?style=social&label=Star)](https://github.com/huggingface/datatrove)<br> [DataTrove](https://github.com/huggingface/datatrove) |​​​ DataTrove 是一个用于大规模处理、过滤和删除重复文本数据的库。它提供了一组预构建的常用处理块以及一个框架，可以轻松添加自定义功能。DataTrove 处理管道与平台无关，可以在本地或 slurm 集群上开箱即用。其（相对）较低的内存使用率和多步骤设计使其非常适合大型工作负载，例如处理 LLM 的训练数据。  |LLM |[Awesome Project第14期](contents/20240122-20240128/20240122-20240128.md) |
| [![Star](https://img.shields.io/github/stars/b4rtaz/distributed-llama.svg?style=social&label=Star)](https://github.com/b4rtaz/distributed-llama)<br> [Distributed Llama](https://github.com/b4rtaz/distributed-llama) |​​​ Distributed Llama在较弱的设备上运行 LLMs 或通过分配工作负载和划分 RAM 使用量使功能强大的设备变得更加强大。该项目证明可以将 LLMs 的工作负载分散到多个设备上并实现显着的加速。分布式 Llama 允许您在内部运行大型 LLMs。该项目使用 TCP 套接字来同步状态。您可以使用家庭路由器轻松配置您的AI集群。目前已支持模型有Llama 2 7B、Llama 2 13B、Llama 2 70B。  |LLM |[Awesome Project第14期](contents/20240122-20240128/20240122-20240128.md) |
| [![Star](https://img.shields.io/github/stars/codefuse-ai/MFTCoder.svg?style=social&label=Star)](https://github.com/codefuse-ai/MFTCoder)<br> [MFTCoder](https://github.com/codefuse-ai/MFTCoder) |​​​ Codefuse-MFTCoder 是一个开源的多任务代码大语言模型项目，包含代码大模型的模型、数据、训练等。是国际首个高精度、高效率、多任务、多模型支持、多训练算法，大模型代码能力微调框架；既支持主流开源的Accelerate+DeepSpeed/FSDP，也支持新开源的ATorch 框架；一个模型同时支持多个任务，会保证多个任务之间的平衡，甚至可以泛化到新的没有见过的任务上去；支持最新的多个开源模型，包括gpt-neox，llama，llama-2，baichuan，Qwen，chatglm2等；支持LoRA和QLoRA，可以用很少的资源去微调很大的模型，且训练速度能满足几乎所有微调场景。  |LLM |[Awesome Project第14期](contents/20240122-20240128/20240122-20240128.md) |
| [![Star](https://img.shields.io/github/stars/alibaba/rtp-llm.svg?style=social&label=Star)](https://github.com/alibaba/rtp-llm)<br> [RTP-LLM](https://github.com/alibaba/rtp-llm) |​​​ rtp-llm 是阿里巴巴大模型预测团队开发的 LLM 推理加速引擎。rtp-llm 在阿里巴巴内部被广泛使用，支持了包括淘宝、天猫、菜鸟、高德、饿了么、AE、Lazada 等多个部门的大模型推理业务。支持剪枝后的不规则模型加载；支持多轮对话上下文 Cache；支持 Speculative Decoding 加速；支持 Medusa 加速；和流行的HuggingFace模型无缝对接，支持多种权重格式。无需额外转换流程；为用户提供高性能、低成本、易用的推理服务，帮助客户和开发者量身定做适合自身业务的推理服务，助力业务增长。  |LLM |[Awesome Project第14期](contents/20240122-20240128/20240122-20240128.md) |
| [哄哄模拟器Web版](https://hong.greatdk.com) |​​​ 哄哄模拟器基于AI技术，你需要使用语言技巧和沟通能力，在限定次数内让对方原谅你，直男必备，快去练习哄你的女朋友吧！女朋友在哪？快去new一个!  |AI应用 |[Awesome Project第14期](contents/20240122-20240128/20240122-20240128.md) |
| [Stable Diffusion教程](https://course.fast.ai/Lessons/part2.html) |​​fast.ai 是全球知名的AI学习网站，该课程的作者是Jeremy Howard ，fast.ai 的创始人，曾任 Kaggle 首席科学家、Etsy数据科学家等职位。 本课程提供30小时以上的视频教学，深入讲解从基础开始实现稳定扩散算法。这一技术曾引发互联网热议，被媒体评价为可能改变人们对网络信息真实性的认知。课程与Stable.ai和Hugging Face的专家合作，确保内容紧跟最新技术进展。除了涵盖Stable Diffusion发布后的论文，课程还教授如何阅读和实践研究论文，帮助学员提升学术研究能力。  |AI教程 |[Awesome Project第15期](contents/20240129-20240204/20240129-20240204.md) |
| [![Star](https://img.shields.io/github/stars/affige/DeepMIR.svg?style=social&label=Star)](https://github.com/affige/DeepMIR)<br> [Deep Learning for Music Analysis and Generation](https://github.com/affige/DeepMIR) |​台大教授的课程《音乐分析与生成的深度学习》教材（2023年秋季），主要是通过深度学习技术解决与音乐相关的各种问题。第一部分是音乐音频信号的分析，涵盖音乐音频的特征提取和表示学习、音乐音频分类、旋律提取、自动音乐转录和音乐源分离等主题。第二部分是关于音乐素材的生成，包括符号域 MIDI 或指法谱，以及音频域音乐信号，例如歌声和器乐。这将涉及深度生成模型，例如生成对抗网络（GAN）、变分自动编码器（VAE）、Transformer和扩散模型。  |AI教程 |[Awesome Project第15期](contents/20240129-20240204/20240129-20240204.md) |
| [![Star](https://img.shields.io/github/stars/morsoli/llm-books.svg?style=social&label=Star)](https://github.com/morsoli/llm-books)<br> [llm-books](https://github.com/morsoli/llm-books) |​​本项目是一个利用LLM构建应用实践笔记。内容包含大语言模型概述、LangChain入门、LlamaIndex 概述、HuggingGPT 实现、LLMOps 专题、Agent 专题及基于大型语言模型的生成式AI。本电子书内容是作者在学习开发基于大语言模型的应用过程中，总结出来的一些经验和方法以及接触到的一些资源，采用理论学习和代码实践相结合的形式。理论学习部分由Langchain、LlamaIndex等开源工具文档、一些最佳实践的技术博客、论文阅读三部分组成。在每个工具的理论学习结束后，辅以实践性代码帮助理解。最后会将各个模块整合起来实现一个信息处理系统。  |LLM |[Awesome Project第15期](contents/20240129-20240204/20240129-20240204.md) |
| [![Star](https://img.shields.io/github/stars/morsoli/llm-books.svg?style=social&label=Star)](https://github.com/morsoli/llm-books)<br> [OLMo](https://github.com/morsoli/llm-books) |​​艾伦人工智能研究所等5机构最近公布了第一个开源语言模型OLMo，包含建模、训练、评估和推理等代码。这是第一个真·完全开源的大模型，几乎将从零开始训练一个大模型过程中的一切数据和资料都开源了，强烈推荐！  |LLM |[Awesome Project第15期](contents/20240129-20240204/20240129-20240204.md) |
| [![Star](https://img.shields.io/github/stars/OpenBMB/MiniCPM.svg?style=social&label=Star)](https://github.com/OpenBMB/MiniCPM)<br> [MiniCPM: 揭示端侧大语言模型的无限潜力](https://github.com/OpenBMB/MiniCPM) |​​MiniCPM 是面壁智能与清华大学自然语言处理实验室共同开源的系列端侧大模型，主体语言模型 MiniCPM-2B 仅有 24亿（2.4B）的非词嵌入参数量。完全开源MiniCPM-2B的模型参数供学术研究和有限商用，在未来还将发布训练过程中的所有Checkpoint和大部分非专有数据供模型机理研究。  |LLM |[Awesome Project第15期](contents/20240129-20240204/20240129-20240204.md) |
| [![Star](https://img.shields.io/github/stars/OpenBMB/OmniLMM.svg?style=social&label=Star)](https://github.com/OpenBMB/OmniLMM)<br> [OmniLMM](https://github.com/OpenBMB/OmniLMM) |​​OmniLMM 是面向图文理解的开源多模态大模型系列。该系列模型接受图像和文本输入，并提供高质量的文本输出。目发布了两个版本的 OmniLMM，旨在实现领先的性能和高效的部署：OmniLMM-12B：相比同规模其他模型在多个基准测试中具有领先性能。OmniLMM-3B：可在终端设备上部署并具备先进的多模态对话能力。  |LLM |[Awesome Project第15期](contents/20240129-20240204/20240129-20240204.md) |
| [![Star](https://img.shields.io/github/stars/tmgthb/Autonomous-Agents.svg?style=social&label=Star)](https://github.com/tmgthb/Autonomous-Agents)<br> [Autonomous Agents](https://github.com/tmgthb/Autonomous-Agents) |长期以来，自主Agent一直被视为通向通用人工智能（AGI）的一条有前途的道路，能够通过自我指导的规划和指令来完成任务。大型语言模型（LLMs）取得了巨大的成功，表明它们具有实现类人智能的潜力。在这种能力的推动下，近年来出现了一种新兴趋势，其中LLMs被用作创建自主Agent的核心协调器，这种战略性的应用旨在模仿类人的决策过程，从而为更复杂和适应性更强的人工智能系统提供一条途径。​​本项目收录了自主Agent(LLM)相关论文列表，每天均会更新。  |LLM |[Awesome Project第15期](contents/20240129-20240204/20240129-20240204.md) |
| [![Star](https://img.shields.io/github/stars/jonyzhang2023/awesome-humanoid-learning.svg?style=social&label=Star)](https://github.com/jonyzhang2023/awesome-humanoid-learning)<br> [awesome-humanoid-learning](https://github.com/jonyzhang2023/awesome-humanoid-learning) |​​项目收录了与人形机器人学习相关的资源精选列表。鉴于人形机器人和双足机器人运动的相似性，也收录了一些关于双足运动的工作以供参考。  |LLM |[Awesome Project第15期](contents/20240129-20240204/20240129-20240204.md) |
| [![Star](https://img.shields.io/github/stars/burglarhobbit/Awesome-Medical-Large-Language-Models.svg?style=social&label=Star)](https://github.com/burglarhobbit/Awesome-Medical-Large-Language-Models)<br> [Awesome-Medical-Large-Language-Models](https://github.com/burglarhobbit/Awesome-Medical-Large-Language-Models) |​​本项目收录了医疗保健和医疗领域相关大型语言模型的精选论文，分为大型语言模型、大型视觉模型、综述论文+临床研究三部分，感兴趣的同学可以查看。  |LLM |[Awesome Project第16期](contents/20240205-20240211/20240205-20240211.md) |
| [![Star](https://img.shields.io/github/stars/segmind/segmoe.svg?style=social&label=Star)](https://github.com/segmind/segmoe)<br> [SegMoE: Segmind Mixture of Diffusion Experts](https://github.com/segmind/segmoe) |​​SegMoE 是一个强大的框架，无需训练即可在几分钟内动态地将稳定扩散模型组合成专家混合物。该框架允许动态创建更大的模型，从而提供更多的知识、更好的依从性和更好的图像质量。它的灵感来自 mergekit 的 mixtral 分支，但适用于稳定扩散模型。  |LLM |[Awesome Project第16期](contents/20240205-20240211/20240205-20240211.md) |
| [![Star](https://img.shields.io/github/stars/QwenLM/Qwen1.5.svg?style=social&label=Star)](https://github.com/QwenLM/Qwen1.5)<br> [Qwen1.5](https://github.com/QwenLM/Qwen1.5) |​​Qwen1.5是阿里云Qwen团队开发的大型语言模型系列Qwen的改进版本。Qwen升级到Qwen1.5，即Qwen2的测试版。与 Qwen 类似，它仍然是一个仅解码器的 Transformer 模型，具有 SwiGLU 激活、RoPE、多头注意力。具有0.5B、1.8B、4B、7B、14B、72B六种型号大小的模型，所有模型都支持 32768 标记的上下文长度。  |LLM |[Awesome Project第16期](contents/20240205-20240211/20240205-20240211.md) |
| [![Star](https://img.shields.io/github/stars/deanxv/coze-discord-proxy.svg?style=social&label=Star)](https://github.com/deanxv/coze-discord-proxy)<br> [coze-discord-proxy](https://github.com/deanxv/coze-discord-proxy) |​字节跳动 Coze 可以免费使用 GPT-4,​代理Discord-Bot对话Coze-Bot，实现API形式请求GPT4对话模型/微调模型。  |LLM |[Awesome Project第16期](contents/20240205-20240211/20240205-20240211.md) |
| [![Star](https://img.shields.io/github/stars/SpursGoZmy/Tabular-LLM.svg?style=social&label=Star)](https://github.com/SpursGoZmy/Tabular-LLM)<br> [Tabular LLM：构建面向表格智能任务的大型语言模型](https://github.com/SpursGoZmy/Tabular-LLM) |​​本项目旨在收集开源的表格智能任务数据集（比如表格问答、表格-文本生成等），将原始数据整理为指令微调格式的数据并微调LLM，进而增强LLM对于表格数据的理解，最终构建出专门面向表格智能任务的大型语言模型。  |LLM |[Awesome Project第16期](contents/20240205-20240211/20240205-20240211.md) |
| [![Star](https://img.shields.io/github/stars/embedchain/embedchain.svg?style=social&label=Star)](https://github.com/embedchain/embedchain)<br> [Embedchain](https://github.com/embedchain/embedchain) |​​Embedchain 是一个开源 RAG 框架，可以轻松创建和部署 AI 应用程序。 Embedchain 的核心遵循“常规但可配置”的设计原则，为软件工程师和机器学习工程师服务。Embedchain 简化了检索增强生成 (RAG) 应用程序的创建，为管理各种类型的非结构化数据提供了无缝流程。它有效地将数据分割成可管理的块，生成相关的嵌入，并将它们存储在矢量数据库中以优化检索。借助一套多样化的 API，它使用户能够提取上下文信息、找到精确的答案或进行交互式聊天对话，根据自己的数据量身定制。  |LLM |[Awesome Project第16期](contents/20240205-20240211/20240205-20240211.md) |
| [![Star](https://img.shields.io/github/stars/explodinggradients/ragas.svg?style=social&label=Star)](https://github.com/explodinggradients/ragas)<br> [Ragas](https://github.com/explodinggradients/ragas) |​​Ragas 是一个框架，可帮助您评估检索增强生成 (RAG) 管道。 RAG 表示一类 LLM 应用程序，它们使用外部数据来增强 LLM 的上下文。现有的工具和框架可以帮助您构建这些管道，但对其进行评估并量化管道性能可能很困难。这就是 Ragas（RAG 评估）发挥作用的地方。Ragas 为您提供基于最新研究的工具，用于评估 LLM 生成的文本，让您深入了解 RAG 管道。 Ragas 可以与您的 CI/CD 集成，以提供持续检查以确保性能。  |LLM |[Awesome Project第16期](contents/20240205-20240211/20240205-20240211.md) |
| [![Star](https://img.shields.io/github/stars/IntelLabs/fastRAG.svg?style=social&label=Star)](https://github.com/IntelLabs/fastRAG)<br> [fastRAG](https://github.com/IntelLabs/fastRAG) |​​fastRAG 是一个用于高效和优化检索增强生成管道的研究框架，结合了最先进的 LLMs 和信息检索。 fastRAG 旨在为研究人员和开发人员提供全面的工具集，以推进检索增强生成。  |LLM |[Awesome Project第16期](contents/20240205-20240211/20240205-20240211.md) |
| [![Star](https://img.shields.io/github/stars/IntelLabs/fastRAG.svg?style=social&label=Star)](https://github.com/IntelLabs/fastRAG)<br> [DLRover：自动分布式深度学习系统](https://github.com/IntelLabs/fastRAG) |​DLRover 使大型 AI 模型的分布式训练变得简单、稳定、快速、绿色。它可以在分布式集群上自动训练深度学习模型。它帮助模型开发人员专注于模型架构，而无需关心硬件加速、分布式运行等任何工程内容。现在，它为 K8s/Ray 上的深度学习训练作业提供自动化运维。可帮助大模型千卡训练有效时间占比超过 95%。同时具有容错性，即分布式训练在发生故障时可以继续运行；具有Flash Checkpoint特性，即分布式训练可以在几秒内从内存检查点恢复故障；还具有自动扩展性，即分布式训练可以扩展/缩减资源，以提高稳定性、吞吐量和资源利用率。  |LLM |[Awesome Project第16期](contents/20240205-20240211/20240205-20240211.md) |
| [![Star](https://img.shields.io/github/stars/gptscript-ai/gptscript.svg?style=social&label=Star)](https://github.com/gptscript-ai/gptscript)<br> [GPTScript](https://github.com/gptscript-ai/gptscript) |​​GPTScript 是一种新的脚本语言，可自动执行与大型语言模型 (LLM)（即 OpenAI）的交互。最终目标是创建完全基于自然语言的编程体验。 GPTScript 的语法很大程度上是自然语言，因此非常容易学习和使用。自然语言提示可以与 bash 和 python 等传统脚本甚至外部 HTTP 服务调用混合。使用 GPTScript，您几乎可以执行任何操作，例如计划假期、编辑文件、运行一些 SQL 或构建 mongodb/flask 应用程序。  |LLM |[Awesome Project第17期](contents/20240212-20240218/20240212-20240218.md) |
| [![Star](https://img.shields.io/github/stars/YangXuanyi/Multi-Agent-GPT.svg?style=social&label=Star)](https://github.com/YangXuanyi/Multi-Agent-GPT)<br> [Multi-Agent-GPT](https://github.com/YangXuanyi/Multi-Agent-GPT) |​​一款基于RAG和agent构建的多模态专家助手GPT。它集成了文本、图像和音频等模态工具。支持本地部署和私有数据库建设。  |LLM |[Awesome Project第17期](contents/20240212-20240218/20240212-20240218.md) |
| [![Star](https://img.shields.io/github/stars/InfiAgent/InfiAgent.svg?style=social&label=Star)](https://github.com/InfiAgent/InfiAgent)<br> [开源Agent框架InfiAgent](https://github.com/InfiAgent/InfiAgent) |​​InfiAgent 旨在支持从头开始构建代理演示，支持代码执行、API 调用、批量推理和沙箱管理。您可以基于InfiAgent轻松构建自己的代理。  |LLM |[Awesome Project第17期](contents/20240212-20240218/20240212-20240218.md) |
| [![Star](https://img.shields.io/github/stars/fixie-ai/ai-benchmarks.svg?style=social&label=Star)](https://github.com/fixie-ai/ai-benchmarks)<br> [ai-benchmarks](https://github.com/fixie-ai/ai-benchmarks) |​​该存储库包含一些用于对流行AI服务的响应延迟进行基准测试的实用程序,支持大型语言模型(LLM)如OpenAI GPT-3.5、GPT-4、Anthropic Claude 2、Google Gemini Pro和PaLM 2 Bison等  |LLM |[Awesome Project第17期](contents/20240212-20240218/20240212-20240218.md) |
| [![Star](https://img.shields.io/github/stars/mlc-ai/web-llm.svg?style=social&label=Star)](https://github.com/mlc-ai/web-llm)<br> [Web LLM](https://github.com/mlc-ai/web-llm) |​​WebLLM 是一个模块化、可定制的 JavaScript 包，可通过硬件加速将语言模型聊天直接带入 Web 浏览器。一切都在浏览器内运行，无需服务器支持，并通过 WebGPU 进行加速。可以带来很多有趣的机会，为每个人构建人工智能助手，并在享受 GPU 加速的同时实现隐私。目前已支持 Llama 2 7B/13B、Mistral 7B 和 WizadMath 等。只需要有一台 64GB 内存的设备，即可运行 Llama 2 70B 模型。  |LLM |[Awesome Project第17期](contents/20240212-20240218/20240212-20240218.md) |
| [![Star](https://img.shields.io/github/stars/netease-youdao/QAnything.svg?style=social&label=Star)](https://github.com/netease-youdao/QAnything)<br> [QAnything](https://github.com/netease-youdao/QAnything) |​网易有道开源的知识库问答引擎QAnything(Question and Answer based on Anything)，​QAnything是致力于支持任意格式文件或数据库的本地知识库问答系统，可断网安装使用。任何格式的本地文件都可以往里扔，即可获得准确、快速、靠谱的问答体验。目前已支持格式: PDF(pdf)，Word(docx)，PPT(pptx)，XLS(xlsx)，Markdown(md)，电子邮件(eml)，TXT(txt)，图片(jpg，jpeg，png)，CSV(csv)，网页链接(html)等。  |LLM |[Awesome Project第17期](contents/20240212-20240218/20240212-20240218.md) |
| [![Star](https://img.shields.io/github/stars/janhq/jan.svg?style=social&label=Star)](https://github.com/janhq/jan)<br> [Jan](https://github.com/janhq/jan) |​​Jan 是 ChatGPT 的开源替代品，可在您的计算机上 100% 离线运行。无需写一行代码，100% 离线本地运行主流开源大语言模型，如 Mistral、Llama、Mixtral 等，支持 Windows、Mac 和 Linux 系统安装，并且拥有高颜值且操作便捷的 UI 界面。  |LLM |[Awesome Project第17期](contents/20240212-20240218/20240212-20240218.md) |
| [![Star](https://img.shields.io/github/stars/dair-ai/ML-YouTube-Courses.svg?style=social&label=Star)](https://github.com/dair-ai/ML-YouTube-Courses)<br> [ML-YouTube-Courses](https://github.com/dair-ai/ML-YouTube-Courses) |由DAIR.AI索引并整理了 YouTube 上一些最好的和最新的机器学习课程。包含Machine Learning、Deep Learning、Scientific Machine Learning、Practical Machine Learning、Natural Language Processing、Computer Vision、Reinforcement Learning、Graph Machine Learning、Multi-Task Learning等几部分。  |AI教程 |[Awesome Project第17期](contents/20240212-20240218/20240212-20240218.md) |
| [Sora原理与技术实战](https://datawhaler.feishu.cn/wiki/RKrCw5YY1iNXDHkeYA5cOF4qnkb) |Datawhale与魔搭社区共同打造的​​Sora技术路径详解，并针对Sora原理中的核心技术点，包括基于diffusion视频生成技术，diffusion Transformers技术解析，video caption技术解析，视频的编解码压缩进行原理介绍，并结合开源模型和代码上手实战。  |LLM |[Awesome Project第18期](contents/20240219-20240225/20240219-20240225.md) |
| [OpenAI视频生成模型Sora的全面解析](https://blog.csdn.net/v_JULY_v/article/details/136143475) |​该博客包含了​OpenAI视频生成模型Sora的全面解析，从ViViT、Diffusion Transformer到NaViT、VideoPoet，包含三个部分，第一部分侧重sora的核心技术解读；第二部分侧重sora相关技术的发展演变，第三部分根据sora的32个reference以窥探其背后的更多细节。  |LLM |[Awesome Project第18期](contents/20240219-20240225/20240219-20240225.md) |
| [![Star](https://img.shields.io/github/stars/all-in-aigc/sorafm.svg?style=social&label=Star)](https://github.com/all-in-aigc/sorafm)<br> [Sora AI 视频生成器](https://github.com/all-in-aigc/sorafm) |​​Sora.FM 的 Sora AI 视频生成器，通过输入prompt生成对应视频。  |LLM |[Awesome Project第18期](contents/20240219-20240225/20240219-20240225.md) |
| [![Star](https://img.shields.io/github/stars/datawhalechina/hugging-multi-agent.svg?style=social&label=Star)](https://github.com/datawhalechina/hugging-multi-agent)<br> [​​Hugging Multi-Agent](https://github.com/datawhalechina/hugging-multi-agent) |​由Datawhale 打造的多智能体实战课程，​Hugging Multi-Agent 是一套专为期望深入了解并实践多智能体系统的开发者设计的实用指南。基于 MetaGPT 旨在帮助读者掌握多智能体系统的核心概念，并提供一套全面的学习路径，从智能体的基础理解到复杂系统的实际开发。  |LLM |[Awesome Project第18期](contents/20240219-20240225/20240219-20240225.md) |
| [秘塔AI搜索](https://metaso.cn/) |​国内一家人工智能科技公司(秘塔科技)推出的​一款AI搜索增强应用，输入搜索关键词后可以直接生成完整答案并给出参考来源。通过语义理解、问题分析、全网搜索对信息进行总结和提炼，为用户呈现清晰明了、重点突出的搜索结果，同时还自动整理了思维导图和大纲，使用户能够迅速地获取关键信息。  |AI搜索工具 |[Awesome Project第18期](contents/20240219-20240225/20240219-20240225.md) |
| [天工AI搜索](https://search.tiangong.cn/) |​由昆仑万维推出的​搜索引擎,采用大语言模型技术，能够通过对话式交互理解用户意图，提供精准、个性化的答案。与传统搜索引擎相比，天工 AI 搜索具备更好的信息提取能力、知识生成能力和意图识别能力。此外，天工AI搜索也即将具备图像、语音等多模态搜索能力，更大程度地释放生产力、提升用户效率。  |AI搜索工具 |[Awesome Project第18期](contents/20240219-20240225/20240219-20240225.md) |
| [魔搭LLM实战训练营](https://www.bilibili.com/video/BV1Fi4y1W7XW) |​​ 魔搭社区前段时间在西安交通大学举办的一门为期7天的大模型带学课程，主要讲述了LLM 大模型基础知识、提示词工程-Prompt Engineering、LLM和多模态模型高效推理实践、大模型微调技术解析和实战、大模型自动评估理论和实战、大模型量化及低成本部署最佳实践及来，亲手做一个A应用！  |AI课程 |[Awesome Project第18期](contents/20240219-20240225/20240219-20240225.md) |
| [通往AGI之路](https://waytoagi.feishu.cn/wiki/QPe5w5g7UisbEkkow8XcDmOpn8e) |​​最近很火的一个知识库，使用飞书文档来撰写，并吸引了大量用户共同维护。整体是一个致力于提供通用人工智能（AGI）相关知识和学习路径的平台。它的目标是帮助人们在学习人工智能的过程中少走弯路，并利用AI技术增强自己的能力。网站提供了一个全面系统的AI学习路径，内容涵盖从AI基础知识到实际应用的各个方面。  |LLM |[Awesome Project第19期](contents/20240226-20240303/20240226-20240303.md) |
| [AI + 视频生成](https://datawhaler.feishu.cn/wiki/FA8UwCrsNiEO0gkh9Uici8RUn5f?fromScene=spaceOverview) |​这个网站是飞书云文档上的一个名为【AI +视频生成】的wiki知识库，由Datawhale组织创建和维护。该知识库的目标是建立一个最开源、开放的免费AI +视频生成知识库，提供有深度的开源学习教程和活动，以促进人工智能（AI）在视频生成领域的应用。  |LLM |[Awesome Project第19期](contents/20240226-20240303/20240226-20240303.md) |
| [![Star](https://img.shields.io/github/stars/mini-sora/minisora.svg?style=social&label=Star)](https://github.com/mini-sora/minisora)<br> [Mini Sora 社区](https://github.com/mini-sora/minisora) |​​Mini Sora 开源社区定位为由社区同学自发组织的开源社区（免费不收取任何费用、不割韭菜），Mini Sora 计划探索 Sora 的实现路径和后续的发展方向：将定期举办 Sora 的圆桌和社区一起探讨可能性与视频生成的现有技术路径探讨。整理了很多Sora相关资料。  |LLM |[Awesome Project第19期](contents/20240226-20240303/20240226-20240303.md) |
| [LLM 资源清单](https://taoofmac.com/space/ai) |​​这个网站是 "Tao of Mac" 的人工智能（AI）资源页面，由 Rui Carmo 创建和维护。页面提供了一个关于人工智能的资源参考表，这些资源包括各种框架、库、技术、工具、应用程序、模型和参考材料。这些资源涵盖了从基础的机器学习到复杂的语言模型和多模态模型等多个领域。  |LLM |[Awesome Project第19期](contents/20240226-20240303/20240226-20240303.md) |
| [![Star](https://img.shields.io/github/stars/lmmlzn/Awesome-LLMs-Datasets.svg?style=social&label=Star)](https://github.com/lmmlzn/Awesome-LLMs-Datasets)<br> [Awesome LLMs Datasets](https://github.com/lmmlzn/Awesome-LLMs-Datasets) |​​由用户 lmmlzn 创建大模型数据集库。这个资源库的目的是收集和整理与大型语言模型（LLMs）相关的数据集。这些数据集可以用于训练、评估和研究大型语言模型，如GPT、BERT等。  |LLM |[Awesome Project第19期](contents/20240226-20240303/20240226-20240303.md) |
| [![Star](https://img.shields.io/github/stars/cooperleong00/Awesome-LLM-Interpretability.svg?style=social&label=Star)](https://github.com/cooperleong00/Awesome-LLM-Interpretability)<br> [Awesome-LLM-Interpretability](https://github.com/cooperleong00/Awesome-LLM-Interpretability) |​​一个由 cooperleong00 创建的资源库，它专注于收集和整理与大型语言模型（LLMs）可解释性相关的资源。这个资源库的目标是为研究人员、开发者和对AI模型可解释性感兴趣的用户提供一个全面的资源列表。包括论文、工具、案例研究和教程等内容。  |LLM |[Awesome Project第19期](contents/20240226-20240303/20240226-20240303.md) |
| [![Star](https://img.shields.io/github/stars/mobvoi/seq-monkey-data.svg?style=social&label=Star)](https://github.com/mobvoi/seq-monkey-data)<br> [出门问问序列猴子开源数据集](https://github.com/mobvoi/seq-monkey-data) |​​序列猴子是出门问问提供的超大规模语言模型，基于其通用的表示与推理能力，支持多轮交互，能够大幅度提高生产效率和数据处理能力，被广泛应用于问答系统、自然语言处理、机器翻译、文本摘要等领域。序列猴子数据集是用于训练序列猴子模型的数据集合，现选择部分数据集向公众开放。序列猴子开源数据集1.0为序列猴子数据集的首个开源版本，涉及中文通用文本语料、古诗今译语料、文本生成语料等领域。  |LLM |[Awesome Project第19期](contents/20240226-20240303/20240226-20240303.md) |
| [![Star](https://img.shields.io/github/stars/microsoft/generative-ai-for-beginners.svg?style=social&label=Star)](https://github.com/microsoft/generative-ai-for-beginners)<br> [面向初学者的生成式AI课程(第2版)](https://github.com/microsoft/generative-ai-for-beginners) |​之前曾介绍过，微软​官方发布了面向初学者的生成式AI课程，最近又更新了第二版，不仅对已有章节的概念、作业等进行了更新，还增加了近期热度非常高的 RAG、AI Agents、Fine-Tuning LLMs 等6个新的章节。  |AI课程 |[Awesome Project第19期](contents/20240226-20240303/20240226-20240303.md) |
| [Prompt Library](https://www.moreusefulthings.com/prompts) |​​该网站收录了老师和学生常用的提示词，提供了多种大模型（GPT4、Gemini、Claude等）的提示词，可以辅助老师们策划课程、制作课程大纲、设计测验，为学生提供课堂反思助手、模拟谈判、提出反面意见等  |LLM |[Awesome Project第20期](contents/20240304-20240310/20240304-20240310.md) |
| [![Star](https://img.shields.io/github/stars/FreedomIntelligence/Apollo.svg?style=social&label=Star)](https://github.com/FreedomIntelligence/Apollo)<br> [Apollo](https://github.com/FreedomIntelligence/Apollo) |​为了将医疗人工智能进步的影响范围扩大到更广泛的人群，我们的目标是开发六种最广泛使用的语言的医疗LLMs，涵盖全球 61 亿人口。这项工作最终创建了 ApolloCorpora 多语言医学数据集和 XMedBench 基准。在多语言医学基准测试中，已发布的Apollo模型在各种相对较小的尺寸（即0.5B、1.8B、2B、6B和7B）下，在同等尺寸的模型中取得了最佳性能。特别是，Apollo-7B 是最先进的多语言医疗LLMs，最高可达 70B。此外，这些精简模型可用于提高大型模型的多语言医疗能力，而无需以代理调整方式进行微调。我们将开源训练语料、代码、模型权重和评估基准。  |LLM |[Awesome Project第20期](contents/20240304-20240310/20240304-20240310.md) |
| [![Star](https://img.shields.io/github/stars/NVIDIA/trt-llm-as-openai-windows.svg?style=social&label=Star)](https://github.com/NVIDIA/trt-llm-as-openai-windows)<br> [TensorRT-LLM as OpenAI API on Windows](https://github.com/NVIDIA/trt-llm-as-openai-windows) |​​此参考可与任何现有的 OpenAI 集成应用程序一起使用，以便在 Windows 上的 GeForce GPU（而不是云）上本地运行 TRT-LLM 推理。  |LLM |[Awesome Project第20期](contents/20240304-20240310/20240304-20240310.md) |
| [![Star](https://img.shields.io/github/stars/RUC-GLAD/GGNN4Science.svg?style=social&label=Star)](https://github.com/RUC-GLAD/GGNN4Science)<br> [几何图神经网络综述：数据结构、模型和应用](https://github.com/RUC-GLAD/GGNN4Science) |​​几何图是一种具有几何特征的特殊图，对于建模许多科学问题至关重要。与典型图不同，几何图通常表现出平移、旋转和反射的物理对称性，使得当前的图神经网络（GNN）无法有效地处理它们。为了解决这个问题，研究人员提出了各种具有不变/等变属性的几何图神经网络，以更好地表征几何图的几何和拓扑。该repo总结了应用程序以及相关数据集，以方便后续研究的方法开发和实验评估。最后讨论了几何 GNN 的挑战和未来的潜在方向。  |LLM |[Awesome Project第20期](contents/20240304-20240310/20240304-20240310.md) |
| [Agent搜索引擎BrainStrom](https://brainstorm.cool) |​引入Agent，模拟创意产生过程中的不同视角进行头脑风暴，可以使用不同的 Agent 角色从不同角度出发思考同一个问题，从而提供更全面的答案。它可以根据问题，自动调用最适合回答问题的 Agent 。  |AI工具 |[Awesome Project第20期](contents/20240304-20240310/20240304-20240310.md) |
| [搜索引擎Globe](https://explorer.globe.engineer) |​​Globe Explorer是一款全新的AI搜索引擎，提供个性化搜索体验，支持多语言搜索，致力于提供高质量的搜索结果。它能够将搜索关键词自动整理成思维导图，帮助用户快速明了地查看信息。  |AI工具 |[Awesome Project第20期](contents/20240304-20240310/20240304-20240310.md) |
| [生成式人工智能导论（ 李宏毅）](https://speech.ee.ntu.edu.tw/~hylee/genai/2024-spring.php) |​​李宏毅老师的新课程《生成式人工智能导论》，该课程将聚焦于基础原理，适合不同背景的学生，让大家都能掌握生成式人工智慧的基本概念。让你不仅只是使用工具，而是理解其背后的原理，修完这门课，当你再次使用ChatGPT 或其他类似工具时，你将能够更深入地理解它们的运作方式，利用它们的潜力和了解他们可能的极限。目标受众为初学者，不需要任何先备知识，也不要求学生事先修过机器学习或人工智慧的课程。  |AI课程 |[Awesome Project第20期](contents/20240304-20240310/20240304-20240310.md) |
| [![Star](https://img.shields.io/github/stars/neuralmagic/nm-vllm.svg?style=social&label=Star)](https://github.com/neuralmagic/nm-vllm)<br> [LLMs高效框架nm-vllm](https://github.com/neuralmagic/nm-vllm) |​是由Neural Magic公司创建和维护的​一套用于LLMs的高吞吐量和内存高效的推理和服务引擎，专注于整合最新的 LLM 优化（例如量化和稀疏性）以增强性能。该仓库提供了安装指南、快速开始教程、以及与OpenAI兼容的服务器集成方法，旨在帮助开发者更容易地部署和使用LLM。  |LLM |[Awesome Project第21期](contents/20240311-20240317/20240311-20240317.md) |
| [![Star](https://img.shields.io/github/stars/HelgeSverre/ollama-gui.svg?style=social&label=Star)](https://github.com/HelgeSverre/ollama-gui)<br> [与本地 LLMs 聊天的 Web 界面Ollama GUI](https://github.com/HelgeSverre/ollama-gui) |​​用于通过 ollama API 与本地 LLMs 聊天的 Web 界面  |LLM |[Awesome Project第21期](contents/20240311-20240317/20240311-20240317.md) |
| [![Star](https://img.shields.io/github/stars/janhq/awesome-local-ai.svg?style=social&label=Star)](https://github.com/janhq/awesome-local-ai)<br> [Awesome Local AI](https://github.com/janhq/awesome-local-ai) |​​这个仓库提供了一个丰富的资源列表，收集和展示一系列本地AI工具和解决方案，涵盖了从推理引擎、用户界面、平台/完整解决方案、开发者工具、代理、训练资源、LLM排行榜、研究论文到社区资源等多个方面。  |LLM |[Awesome Project第21期](contents/20240311-20240317/20240311-20240317.md) |
| [![Star](https://img.shields.io/github/stars/merveenoyan/awesome-osml-for-devs.svg?style=social&label=Star)](https://github.com/merveenoyan/awesome-osml-for-devs)<br> [Awesome Open-source Machine Learning for Developers](https://github.com/merveenoyan/awesome-osml-for-devs) |​由merveenoyan创建的，旨在为开发者提供一个关于开源机器学习（OSML）的资源列表。这个仓库收集了各种机器学习相关的工具、库、框架、教程和其他有用的资源。  |LLM |[Awesome Project第21期](contents/20240311-20240317/20240311-20240317.md) |
| [![Star](https://img.shields.io/github/stars/shivendrra/SmallLanguageModel-project.svg?style=social&label=Star)](https://github.com/shivendrra/SmallLanguageModel-project)<br> [小语言模型](https://github.com/shivendrra/SmallLanguageModel-project) |提供了一个从零开始构建小型语言模型（SLM）所需的所有代码和资源，包含了从数据收集到模型架构文件、分词器和训练文件的所有内容，适合那些对自然语言处理和机器学习感兴趣的开发者和研究者。  |LLM |[Awesome Project第21期](contents/20240311-20240317/20240311-20240317.md) |
| [LLM 应用开发实践笔记](https://aitutor.liduos.com/01-llm/01-1.html) |​​学习开发基于大语言模型的应用过程中，总结出来的一些经验和方法以及接触到的一些资源，采用理论学习和代码实践相结合的形式。  |AI教程 |[Awesome Project第21期](contents/20240311-20240317/20240311-20240317.md) |
| [Sam Altman的创业手册](https://jxp73q7qjsg.feishu.cn/docx/WCNZdKDa4o2eUrxK5ElcfBXEnah?continueFlag=3a6d0325757abca6e8cbb95b53b664d3) |​​为创业者提供了一套全面的创业指南，涵盖了从想法的孕育、团队的构建、产品的开发到执行策略的实施等各个方面。文章强调了创业的艰辛和挑战，同时也提供了实用的建议和策略，帮助创业者避免常见陷阱，专注于构建伟大的产品和公司。  |其他 |[Awesome Project第21期](contents/20240311-20240317/20240311-20240317.md) |
| [![Star](https://img.shields.io/github/stars/omkarcloud/botasaurus.svg?style=social&label=Star)](https://github.com/omkarcloud/botasaurus)<br> [全能的网络爬虫框架Botasaurus](https://github.com/omkarcloud/botasaurus) |​​Botasaurus是一个强大且灵活的网络爬虫工具，提供了多种设置来根据特定需求定制爬取过程，提高了效率和便利性。无论是处理多个数据点、需要并行处理还是需要缓存结果，Botasaurus都提供了简化爬取任务所需的功能。  |其他 |[Awesome Project第21期](contents/20240311-20240317/20240311-20240317.md) |
| [![Star](https://img.shields.io/github/stars/hpcaitech/Open-Sora.svg?style=social&label=Star)](https://github.com/hpcaitech/Open-Sora)<br> [Open-Sora： 完全开源的高效复现类Sora视频生成方案](https://github.com/hpcaitech/Open-Sora) |​​Open-Sora项目是一项致力于高效制作高质量视频，并使所有人都能使用其模型、工具和内容的计划。 通过采用开源原则，Open-Sora 不仅实现了先进视频生成技术的低成本普及，还提供了一个精简且用户友好的方案，简化了视频制作的复杂性。 通过 Open-Sora，希望更多开发者一起探索内容创作领域的创新、创造和包容。  |LLM |[Awesome Project第22期](contents/20240318-20240324/20240318-20240324.md) |
| [![Star](https://img.shields.io/github/stars/rotemweiss57/gpt-newspaper.svg?style=social&label=Star)](https://github.com/rotemweiss57/gpt-newspaper)<br> [GPT Newspaper](https://github.com/rotemweiss57/gpt-newspaper) |GPT Newspaper通过AI技术，根据用户的兴趣和偏好，聚合、编写、设计和编辑内容，从而提供个性化的新闻阅读体验。包含六个专门的子代理，每个代理在创建个性化报纸的过程中扮演关键角色，包括搜索代理、策展代理、写作代理、批评代理、设计代理、编辑代理和发布代理。  |LLM |[Awesome Project第22期](contents/20240318-20240324/20240318-20240324.md) |
| [![Star](https://img.shields.io/github/stars/jonfairbanks/local-rag.svg?style=social&label=Star)](https://github.com/jonfairbanks/local-rag)<br> [localRAG](https://github.com/jonfairbanks/local-rag) |​​本地RAG项目，旨在实现在本地网络环境中使用大型语言模型（LLMs）进行文件摄入和检索增强生成（RAG），而不依赖第三方服务，确保用户敏感数据的安全。  |LLM |[Awesome Project第22期](contents/20240318-20240324/20240318-20240324.md) |
| [![Star](https://img.shields.io/github/stars/gregorojstersek/resources-to-become-a-great-engineering-leader.svg?style=social&label=Star)](https://github.com/gregorojstersek/resources-to-become-a-great-engineering-leader)<br> [100多种资源可帮助您成为出色的工程领导者](https://github.com/gregorojstersek/resources-to-become-a-great-engineering-leader) |​​该Repo旨在帮助工程领导者成长，提供了一系列精选的书籍、博客、新闻通讯和行业领袖的链接，覆盖了系统设计、领导力、软件工程、产品思维和数据科学等多个领域，鼓励通过有针对性地学习和社区贡献来提升个人技能。  |LLM |[Awesome Project第22期](contents/20240318-20240324/20240318-20240324.md) |
| [![Star](https://img.shields.io/github/stars/cantbebetter2/Awesome-Diffusion-Distillation.svg?style=social&label=Star)](https://github.com/cantbebetter2/Awesome-Diffusion-Distillation)<br> [Awesome Diffusion Distillation](https://github.com/cantbebetter2/Awesome-Diffusion-Distillation) |该repo整理了​​有关扩散蒸馏的论文、文档、代码列表。此存储库收集了扩散模型的各种蒸馏方法。  |LLM |[Awesome Project第22期](contents/20240318-20240324/20240318-20240324.md) |
| [![Star](https://img.shields.io/github/stars/MLGroup-JLU/LLM-data-aug-survey.svg?style=social&label=Star)](https://github.com/MLGroup-JLU/LLM-data-aug-survey)<br> [有关使用大型模型进行数据增强的论文和资源](https://github.com/MLGroup-JLU/LLM-data-aug-survey) |​​本文采用综合视角，对大型模型驱动的数据增强方法进行了详尽的回顾。我们首先将相关研究分为三个主要类别：图像增强、文本增强和配对数据增强。接下来，我们深入研究与基于大型模型的数据增强相关的各种数据后处理技术。然后，我们的讨论扩展到涵盖这些数据增强方法在自然语言处理、计算机视觉和音频信号处理中的一系列应用。我们继续评估不同场景中基于大型模型的数据增强的成功和局限性。在总结我们的审查时，我们强调了数据增强领域未来探索的潜在挑战和途径。  |LLM |[Awesome Project第22期](contents/20240318-20240324/20240318-20240324.md) |
| [我从 900 个最流行的开源 AI 工具中学到了什么](https://huyenchip.com//2024/03/14/ai-oss.html) |​​文章分享了作者对900个最受欢迎的开源人工智能工具进行分析后的见解和发现。作者将AI技术栈视为由四层组成：基础设施、模型开发、应用开发和应用程序。  |LLM |[Awesome Project第22期](contents/20240318-20240324/20240318-20240324.md) |
| [![Star](https://img.shields.io/github/stars/yuunnn-w/RWKV_Pytorch.svg?style=social&label=Star)](https://github.com/yuunnn-w/RWKV_Pytorch)<br> [RWKV_Pytorch](https://github.com/yuunnn-w/RWKV_Pytorch) |​​这是一个用纯Pytorch原生实现的RWKV大语言模型的推理框架，官方的原生实现过于复杂且无法拓展生态，支持batch推理,代码整洁，容易阅读和二次开发;支持导出并推理onnx格式模型！  |LLM |[Awesome Project第22期](contents/20240318-20240324/20240318-20240324.md) |
| [![Star](https://img.shields.io/github/stars/harry0703/MoneyPrinterTurbo.svg?style=social&label=Star)](https://github.com/harry0703/MoneyPrinterTurbo)<br> [利用大模型，一键生成短视频](https://github.com/harry0703/MoneyPrinterTurbo) |​一键生成短视频，用户只需提供视频主题或关键词，系统便能自动生成视频文案、素材、字幕和背景音乐，并合成高清短视频。  |LLM |[Awesome Project第23期](contents/20240325-20240331/20240325-20240331.md) |
| [![Star](https://img.shields.io/github/stars/misbahsy/RAGTune.svg?style=social&label=Star)](https://github.com/misbahsy/RAGTune)<br> [RAGTune](https://github.com/misbahsy/RAGTune) |​​AGTune是一个为RAG管道提供调优和评估的自动化工具，它支持多种大型语言模型和嵌入模型，提供了丰富的评估指标，并允许用户进行定制化设置。  |LLM |[Awesome Project第23期](contents/20240325-20240331/20240325-20240331.md) |
| [![Star](https://img.shields.io/github/stars/allwefantasy/auto-coder.svg?style=social&label=Star)](https://github.com/allwefantasy/auto-coder)<br> [​Auto-Coder](https://github.com/allwefantasy/auto-coder) |​​Auto-Coder项目为开发者提供了一个强大的工具，通过AI的辅助，可以大幅提高编程效率和代码质量。无论是生成代码上下文还是直接生成代码结果，Auto-Coder都能够满足开发者的不同需求，使得AI编程变得更加简单和高效。  |LLM |[Awesome Project第23期](contents/20240325-20240331/20240325-20240331.md) |
| [![Star](https://img.shields.io/github/stars/agiresearch/AIOS.svg?style=social&label=Star)](https://github.com/agiresearch/AIOS)<br> [AIOS: LLM Agent Operating System](https://github.com/agiresearch/AIOS) |​​AIOS是一个操作系统，它将大型语言模型作为操作系统的核心，优化资源分配，促进代理之间的上下文切换，支持代理的并发执行，为代理提供工具服务，维护代理的访问控制，并为LLM代理开发者提供丰富的工具包。  |LLM |[Awesome Project第23期](contents/20240325-20240331/20240325-20240331.md) |
| [![Star](https://img.shields.io/github/stars/NiuTrans/ABigSurveyOfLLMs.svg?style=social&label=Star)](https://github.com/NiuTrans/ABigSurveyOfLLMs)<br> [LLMs Survey](https://github.com/NiuTrans/ABigSurveyOfLLMs) |​​本项目旨在提供一个全面的调查，涵盖大型预训练语言模型的最新进展，包括模型架构、训练技术、应用场景和未来发展趋势等。  |LLM |[Awesome Project第23期](contents/20240325-20240331/20240325-20240331.md) |
| [![Star](https://img.shields.io/github/stars/stitionai/devika.svg?style=social&label=Star)](https://github.com/stitionai/devika)<br> [Agentic AI 软件工程师](https://github.com/stitionai/devika) |​​Devika 是一名代理人工智能软件工程师，可以理解高级人类指令，将其分解为步骤，研究相关信息，并编写代码来实现给定的目标。 Devika 的目标是成为 Cognition AI 的 Devin 的有竞争力的开源替代品。  |LLM |[Awesome Project第23期](contents/20240325-20240331/20240325-20240331.md) |
| [![Star](https://img.shields.io/github/stars/aishwaryanr/awesome-generative-ai-guide.svg?style=social&label=Star)](https://github.com/aishwaryanr/awesome-generative-ai-guide)<br> [awesome-generative-ai-guide](https://github.com/aishwaryanr/awesome-generative-ai-guide) |​​专注于生成性人工智能（Generative AI）领域，旨在为那些对生成模型、深度学习和人工智能感兴趣的研究人员、开发者和爱好者提供一个全面的指南。该项目包含了大量的资源链接，如学术论文、教程、博客文章、开源项目和工具等，涵盖了从基础概念到高级技术应用的各个方面。它不仅有助于初学者快速了解和入门生成性AI，也为经验丰富的研究者提供了深入研究和探索该领域最新进展的宝贵资料。  |LLM |[Awesome Project第23期](contents/20240325-20240331/20240325-20240331.md) |
| [![Star](https://img.shields.io/github/stars/OpenDevin/OpenDevin.svg?style=social&label=Star)](https://github.com/OpenDevin/OpenDevin)<br> [OpenDevin](https://github.com/OpenDevin/OpenDevin) |这是一个旨在复制 Devin 的开源项目，Devin 是一位自主人工智能软件工程师，能够执行复杂的工程任务并在软件开发项目上与用户积极协作。该项目致力于通过开源社区的力量复制、增强和创新 Devin。目标是解决代码LLMs在实际场景中面临的挑战，制作出对社区有重大贡献的作品，并为未来的进步铺平道路。  |LLM |[Awesome Project第23期](contents/20240325-20240331/20240325-20240331.md) |
| [![Star](https://img.shields.io/github/stars/JiaqiLi404/IAmDirector-Text2Video-NextJS-Client.svg?style=social&label=Star)](https://github.com/JiaqiLi404/IAmDirector-Text2Video-NextJS-Client)<br> [IAmDirector - 每个人都能成为导演](https://github.com/JiaqiLi404/IAmDirector-Text2Video-NextJS-Client) |​​本项目开源基于NextJS的前端， 希望能够提供一个用于生成式AI的文字转视频， 尤其是电影从编剧到视频生成的Web前端平台参考。这是一个免费试用AI视频创作平台，集成了基于GPT的视频剧本生成和视频生成功能。 我们的理想是让每个人都能成为导演，以最快的方式将日常中的任何创意转化为高质量的视频， 无论是电影、营销视频、还是自媒体视频。  |AI工具 |[Awesome Project第24期](contents/20240401-20240407/20240401-20240407.md) |
| [![Star](https://img.shields.io/github/stars/unit-mesh/edge-infer.svg?style=social&label=Star)](https://github.com/unit-mesh/edge-infer)<br> [EdgeInfer](https://github.com/unit-mesh/edge-infer) |​​EdgeInfer 旨在资源受限的设备上运行小型 AI 模型（包括向量化和 Onnx 模型），如 Android、iOS 或 MCUs，实现高效的边缘智能，用于实时决策。  |AI工具 |[Awesome Project第24期](contents/20240401-20240407/20240401-20240407.md) |
| [![Star](https://img.shields.io/github/stars/OpenBMB/ChatDev.svg?style=social&label=Star)](https://github.com/OpenBMB/ChatDev)<br> [ChatDev](https://github.com/OpenBMB/ChatDev) |​​ChatDev是一家虚拟软件公司，通过担任不同角色的各种智能代理进行运营，包括首席执行官、首席产品官、首席技术官、程序员、审阅者、测试员、美术设计师。这些代理形成了一个多代理组织结构，并因“通过编程彻底改变数字世界”的使命而团结在一起。 ChatDev 中的代理通过参加专门的功能研讨会进行协作，包括设计、编码、测试和记录等任务。ChatDev 的主要目标是提供一个易于使用、高度可定制和可扩展的框架，该框架基于大型语言模型（LLMs），并作为研究集体智慧的理想场景。  |AI工具 |[Awesome Project第24期](contents/20240401-20240407/20240401-20240407.md) |
| [![Star](https://img.shields.io/github/stars/wandb/openui.svg?style=social&label=Star)](https://github.com/wandb/openui)<br> [OpenUI](https://github.com/wandb/openui) |构建 UI 组件可能会很困难。 OpenUI 的目标是让这个过程变得有趣、快速且灵活。这也是我们在 W&B 中使用的工具，用于测试和原型化我们的下一代工具，以便在 LLM 之上构建强大的应用程序。O​​penUI 让您可以发挥想象力来描述 UI，然后查看它的实时渲染。您可以要求更改并将 HTML 转换为 React、Svelte、Web Components 等。  |AI工具 |[Awesome Project第24期](contents/20240401-20240407/20240401-20240407.md) |
| [![Star](https://img.shields.io/github/stars/princeton-nlp/SWE-agent.svg?style=social&label=Star)](https://github.com/princeton-nlp/SWE-agent)<br> [SWE-agent](https://github.com/princeton-nlp/SWE-agent) |​SWE-agent，是一个基于软件工程（SWE）的智能代理，旨在自动化软件工程任务，提高开发效率和质量。​SWE-agent 将 LM（例如 GPT-4）转变为软件工程代理，可以修复真实 GitHub 存储库中的错误和问题。SWE-agent利用自然语言处理和机器学习技术来理解和执行与软件工程相关的指令。它可以被用来自动化代码审查、bug检测、代码生成等任务，从而减轻开发人员的负担，让他们能够专注于更高层次的创造性工作。  |AI工具 |[Awesome Project第24期](contents/20240401-20240407/20240401-20240407.md) |
| [![Star](https://img.shields.io/github/stars/jwasham/coding-interview-university.svg?style=social&label=Star)](https://github.com/jwasham/coding-interview-university)<br> [Coding Interview University](https://github.com/jwasham/coding-interview-university) |​​该项目提供了一个详尽的多月学习计划，包括数据结构、算法、计算机网络、操作系统等计算机科学基础知识，以及面试技巧和简历准备建议。它推荐了一系列书籍和视频资源，并强调了实践编程问题的重要性。此外，项目还包括了额外的学习主题，如系统设计和编译器原理，以及一些Unix命令行工具的介绍。  |AI教程 |[Awesome Project第24期](contents/20240401-20240407/20240401-20240407.md) |
| [![Star](https://img.shields.io/github/stars/PandaBearLab/prompt-tutorial.svg?style=social&label=Star)](https://github.com/PandaBearLab/prompt-tutorial)<br> [关于如何编写大模型的prompt的一系列课](https://github.com/PandaBearLab/prompt-tutorial) |​​提供了一系列教程和指导，旨在帮助用户有效地与大型语言模型交互。该项目涵盖了编写有效提示词的技巧、迭代优化方法、文本内容生成、自然语言处理和创建聊天机器人等方面的内容。通过介绍CRISPE等prompt框架和提供实用工具链，提高用户在prompt engineering方面的技能。  |AI教程 |[Awesome Project第24期](contents/20240401-20240407/20240401-20240407.md) |
| [![Star](https://img.shields.io/github/stars/ai-vip/stable-diffusion-tutorial.svg?style=social&label=Star)](https://github.com/ai-vip/stable-diffusion-tutorial)<br> [Stable Diffusion教程](https://github.com/ai-vip/stable-diffusion-tutorial) |​​全网最全Stable Diffusion全套教程，从入门到进阶，耗时三个月制作,包含软件介绍和安装、基本使用  |AI教程 |[Awesome Project第24期](contents/20240401-20240407/20240401-20240407.md) |
| [![Star](https://img.shields.io/github/stars/openai/simple-evals.svg?style=social&label=Star)](https://github.com/openai/simple-evals)<br> [大模型评估库simple-evals](https://github.com/openai/simple-evals) |​simple-evals是由OpenAI创建的轻量级库，旨在提供一个透明和标准化的方式来评估语言模型的性能。该库特别强调零样本和思维链的评估设置，并通过简单的指令来测试模型的实际应用性能。目前，它包含了多种评估任务，如MMLU、MATH、GPQA等，以及对不同语言模型API的采样接口。  |LLM |[Awesome Project第25期](contents/20240408-20240414/20240408-20240414.md) |
| [![Star](https://img.shields.io/github/stars/JShollaj/awesome-llm-web-ui.svg?style=social&label=Star)](https://github.com/JShollaj/awesome-llm-web-ui)<br> [Awesome LLM Web UI](https://github.com/JShollaj/awesome-llm-web-ui) |​​该存储库致力于列出最出色的大型语言模型 (LLM) Web 用户界面，可促进与强大的 AI 模型的交互。探索并编录了用于与 LLMs 交互的最直观、功能丰富且创新的 Web 界面。这些 UI 范围从简单的聊天机器人到配备 PDF 生成、网络搜索等功能的综合平台。  |LLM |[Awesome Project第25期](contents/20240408-20240414/20240408-20240414.md) |
| [![Star](https://img.shields.io/github/stars/mosaicml/llm-eval-dashboard.svg?style=social&label=Star)](https://github.com/mosaicml/llm-eval-dashboard)<br> [用于可视化 LLM 评估的 Streamlit 应用程序](https://github.com/mosaicml/llm-eval-dashboard) |​​这个 Streamlip 应用程序接收一个 Markdown 表（行：模型，列：评估）并使用雷达图将其可视化。  |LLM |[Awesome Project第25期](contents/20240408-20240414/20240408-20240414.md) |
| [![Star](https://img.shields.io/github/stars/XiudingCai/Awesome-Mamba-Collection.svg?style=social&label=Star)](https://github.com/XiudingCai/Awesome-Mamba-Collection)<br> [Awesome-Mamba-Collection](https://github.com/XiudingCai/Awesome-Mamba-Collection) |​​该存储库是与 Mamba 相关的论文、教程、视频和其他有价值资源的精选集合。无论您是初学者还是经验丰富的用户，本合集旨在为 Mamba 的所有内容提供全面的参考。探索最新的研究论文、深入了解有用的教程并发现富有洞察力的视频，以增强您对 Mamba 的理解和熟练程度。  |LLM |[Awesome Project第25期](contents/20240408-20240414/20240408-20240414.md) |
| [![Star](https://img.shields.io/github/stars/zhangyikaii/LAMDA-ZhiJian.svg?style=social&label=Star)](https://github.com/zhangyikaii/LAMDA-ZhiJian)<br> [执简：为预训练模型复用提供快速部署的统一方案](https://github.com/zhangyikaii/LAMDA-ZhiJian) |​​ZhiJian (执简驭繁) 是一个基于PyTorch框架的模型复用工具包，为再次利用许多基座预训练模型以及已有任务上的已训练模型，充分提取它们蕴含的知识并激发目标任务上的学习，提供了全面且统一的复用方案。模型复用通过适配网络结构、定制学习方式以及优化推理策略来利用这些预训练模型，来进一步加速和强化目标任务上的学习，为了全面而简洁地考虑各种模型复用策略，ZhiJian 将复用方法归类为三个主要模块：构建者，微调者，和融合者，它们分别与目标任务部署时模型准备阶段、学习阶段和推理阶段相对应。  |LLM |[Awesome Project第25期](contents/20240408-20240414/20240408-20240414.md) |
| [![Star](https://img.shields.io/github/stars/karpathy/llm.c.svg?style=social&label=Star)](https://github.com/karpathy/llm.c)<br> [使用简单、原始的 C/CUDA 进行训练LLM](http://github.com/karpathy/llm.c) |​​LLM 使用简单、纯 C/CUDA 进行训练。不需要 245MB 的 PyTorch 或 107MB 的 cPython。例如，训练 GPT-2（CPU、fp32）需要在单个文件中包含大约 1,000 行干净的代码。它可以立即编译并运行，并且与 PyTorch 参考实现完全匹配。  |LLM |[Awesome Project第25期](contents/20240408-20240414/20240408-20240414.md) |
| [![Star](https://img.shields.io/github/stars/Academic-Hammer/HammerLLM.svg?style=social&label=Star)](https://github.com/Academic-Hammer/HammerLLM)<br> [1.4B参数量的HammerLLM](https://github.com/Academic-Hammer/HammerLLM) |​​该项目是一个小型大型语言模型（sLLM），拥有14亿参数，基于Llama 2架构。HammerLLM支持中英文以及代码生成，具有简单高效的训练代码库、完整的开源资源（包括模型权重、环境、代码库和超参数）以及与类似规模的先进sLLM相当的性能。此外，它还拥有高压缩率的分词器，能100%覆盖中文字符。项目页面还提供了使用示例代码、不同场景下的文本生成案例、预训练模型信息、性能测试结果、分词器对比、训练进度和贡献指南等详细信息。  |LLM |[Awesome Project第25期](contents/20240408-20240414/20240408-20240414.md) |
| [![Star](https://img.shields.io/github/stars/btbytes/cf845f9ade1cb34348110c14c8c49cea.svg?style=social&label=Star)](https://github.com/btbytes/cf845f9ade1cb34348110c14c8c49cea)<br> [LLM训练指南](https://gist.github.com/btbytes/cf845f9ade1cb34348110c14c8c49cea) |​教程​系统地讲解了如何使用 Transformers 库和 Transformer 网络架构训练大型语言模型 (LLM)，包含Transformer 架构、预训练、微调、低秩适应、从头开始训练、本地微调、训练超参数等内容。  |AI教程 |[Awesome Project第25期](contents/20240408-20240414/20240408-20240414.md) |
| [![Star](https://img.shields.io/github/stars/owenliang/qwen-vllm.svg?style=social&label=Star)](https://github.com/owenliang/qwen-vllm)<br> [qwen-vllm](https://github.com/owenliang/qwen-vllm) |​​qwen-vllm是一个开源的推理部署演示，专注于展示如何在生产环境中搭建高并发的VLLM（通义千问）推理服务，包括离线和在线推理的实现，以及基于asyncio的异步处理和流式返回技术。项目还提供了详细的安装指南和使用示例，旨在帮助开发者理解和应用vLLM技术进行高效的自然语言处理任务。  |LLM |[Awesome Project第26期](contents/20240415-20240421/20240415-20240421.md) |
| [![Star](https://img.shields.io/github/stars/vince-lam/awesome-local-llms.svg?style=social&label=Star)](https://github.com/vince-lam/awesome-local-llms)<br> [Awesome Local LLMs](https://github.com/vince-lam/awesome-local-llms) |本仓库​​旨在汇总和比较开源的本地大型语言模型（LLM）推理项目。该项目通过GitHub仓库的指标（如星标数、贡献者数量、问题、发布和最后提交时间）来评估各个项目的受欢迎程度和活跃维护情况。它包含了从后端推理引擎到前端用户界面，以及一体化桌面应用程序的各种工具，  |LLM |[Awesome Project第26期](contents/20240415-20240421/20240415-20240421.md) |
| [![Star](https://img.shields.io/github/stars/elicit/machine-learning-list.svg?style=social&label=Star)](https://github.com/elicit/machine-learning-list)<br> [机器学习阅读清单 Elicit Machine Learning Reading List](github.com/elicit/machine-learning-list) |​​该项目是一个资源列表，专注于收集和整理与机器学习相关的各种资源，旨在为对机器学习感兴趣的开发者、研究人员和学习者提供一个集中的信息源。尽管具体的资源内容无法从提供的网页内容中得知，但通常这类列表会包括教程、课程、书籍、论文、开源项目、工具和库等，以帮助用户更好地理解和应用机器学习技术。通过这个项目，用户可以发现和探索机器学习领域的最新进展和实用工具，从而促进他们在该领域的学习和研究工作。  |LLM |[Awesome Project第26期](contents/20240415-20240421/20240415-20240421.md) |
| [![Star](https://img.shields.io/github/stars/stanford-oval/storm.svg?style=social&label=Star)](https://github.com/stanford-oval/storm)<br> [AI 写作工具 STORM](github.com/stanford-oval/storm) |​​STORM是由斯坦福大学团队开发的一种基于大型语言模型（LLM）的知识整合系统，旨在从零开始撰写类似维基百科的文章。该系统通过互联网搜索进行研究，分为两个阶段：预写阶段和写作阶段。在预写阶段，STORM通过互联网研究收集参考资料并生成大纲；在写作阶段，系统利用大纲和参考资料生成带有引用的全文文章。STORM采用多角度提问和模拟对话的策略来提高问题的深度和广度，并通过模块化的方式实现。该系统虽然不能直接生成可出版的文章，但经验丰富的维基百科编辑发现它在预写阶段非常有帮助。用户可以通过在线演示体验STORM，并提供反馈以帮助改进系统。  |LLM |[Awesome Project第26期](contents/20240415-20240421/20240415-20240421.md) |
| [![Star](https://img.shields.io/github/stars/nilsherzig/LLocalSearch.svg?style=social&label=Star)](https://github.com/nilsherzig/LLocalSearch)<br> [使用 LLM 代理的完全本地运行的搜索聚合器](https://github.com/nilsherzig/LLocalSearch) |​​LLocalSearch 是一个使用 LLM 代理的完全本地运行的搜索聚合器。用户可以提出问题，系统将使用LLMs链来查找答案。用户可以看到代理的进度和最终的答案。不需要 OpenAI 或 Google API 密钥。  |LLM |[Awesome Project第26期](contents/20240415-20240421/20240415-20240421.md) |
| [![Star](https://img.shields.io/github/stars/Developer-Y/cs-video-courses.svg?style=social&label=Star)](https://github.com/Developer-Y/cs-video-courses)<br> [List of Computer Science courses with video lectures](https://github.com/Developer-Y/cs-video-courses) |​​汇集了一系列包含视频讲座的计算机科学课程。这个项目旨在为那些希望通过视觉和听觉材料学习计算机科学的人们提供一个便捷的途径。用户可以在这个仓库中找到各种主题的课程，从基础的编程概念到高级的计算机科学理论，这些课程可能来自于世界各地的顶尖大学或专业机构。通过这个项目，开发者和学习者可以轻松地访问和探索丰富的教育资源，从而提升他们的技术能力和知识水平。  |LLM |[Awesome Project第26期](contents/20240415-20240421/20240415-20240421.md) |
| [Google 学术搜索PDF阅读器](https://chromewebstore.google.com/detail/google-%E5%AD%A6%E6%9C%AF%E6%90%9C%E7%B4%A2-pdf-%E9%98%85%E8%AF%BB%E5%99%A8/dahenjhkoodjbpjheillcadbppiidmhp) |​​安装学术搜索阅读器后，就能在 Chrome 中以全新方式查看所有网站上的 PDF 文件。提升论文阅读体验：追踪参考文献、重点浏览大纲、跳转到图表、引用并保存。  |学术工具 |[Awesome Project第26期](contents/20240415-20240421/20240415-20240421.md) |
| [![Star](https://img.shields.io/github/stars/naxiaoduo/1000UserGuide.svg?style=social&label=Star)](https://github.com/naxiaoduo/1000UserGuide)<br> [1000UserGuide](https://github.com/naxiaoduo/1000UserGuide) |​​对独立开发者和创业者来说，找到前1000个早期用户太关键了。这里精心整理了300多个国内外渠道，适合独立开发者和创业者推广产品的渠道。  |其他 |[Awesome Project第26期](contents/20240415-20240421/20240415-20240421.md) |
| [![Star](https://img.shields.io/github/stars/LlamaFamily/Llama-Chinese.svg?style=social&label=Star)](https://github.com/LlamaFamily/Llama-Chinese)<br> [Llama中文社区](https://github.com/LlamaFamily/Llama-Chinese) |​​该Repo是一个专注于Llama模型中文优化的技术社区平台，提供包括Atom-7B在内的多种中文预训练模型，以及Llama2和Llama3系列模型的下载和使用指南。此外，该社区还提供模型预训练、微调、量化和部署加速的详细教程，丰富的社区资源如算力、数据集、论坛支持，以及模型评测和学习中心。  |LLM |[Awesome Project第27期](contents/20240422-20240428/20240422-20240428.md) |
| [![Star](https://img.shields.io/github/stars/hpcaitech/Open-Sora.svg?style=social&label=Star)](https://github.com/hpcaitech/Open-Sora)<br> [Open-Sora： 完全开源的高效复现类Sora视频生成方案](https://github.com/hpcaitech/Open-Sora) |​​Open-Sora项目是一项致力于高效制作高质量视频，并使所有人都能使用其模型、工具和内容的计划。 通过采用开源原则，Open-Sora 不仅实现了先进视频生成技术的低成本普及，还提供了一个精简且用户友好的方案，简化了视频制作的复杂性。 通过 Open-Sora，我们希望更多开发者一起探索内容创作领域的创新、创造和包容。  |LLM |[Awesome Project第27期](contents/20240422-20240428/20240422-20240428.md) |
| [![Star](https://img.shields.io/github/stars/pytorch/torchtitan.svg?style=social&label=Star)](https://github.com/pytorch/torchtitan)<br> [用于大模型训练的原生 PyTorch 库](https://github.com/pytorch/torchtitan) |​​torchtitan 是使用本机 PyTorch 进行大规模 LLM 训练的概念验证。它是（并将继续是）一个以干净、最小的代码库展示 PyTorch 最新分布式训练功能的存储库。 torchtitan 是对任何大型 LLM 训练代码库的补充，而不是替代，例如 Megatron、Megablocks、LLM Foundry、Deepspeed 等。相反，我们希望torchtitan 中展示的功能将很快被这些​​代码库采用。  |LLM |[Awesome Project第27期](contents/20240422-20240428/20240422-20240428.md) |
| [![Star](https://img.shields.io/github/stars/McGill-NLP/webllama.svg?style=social&label=Star)](https://github.com/McGill-NLP/webllama)<br> [WebLlama](https://github.com/McGill-NLP/webllama) |​​我们项目的目标是构建有效的以人为中心的代理来浏览网络。我们不想取代用户，而是为他们配备强大的助手。  |LLM |[Awesome Project第27期](contents/20240422-20240428/20240422-20240428.md) |
| [![Star](https://img.shields.io/github/stars/cohere-ai/cohere-toolkit.svg?style=social&label=Star)](https://github.com/cohere-ai/cohere-toolkit)<br> [快速构建和部署 RAG 应用程序的工具箱](https://github.com/cohere-ai/cohere-toolkit) |​​Toolkit 是预构建组件的集合，使用户能够快速构建和部署 RAG 应用程序。  |LLM |[Awesome Project第27期](contents/20240422-20240428/20240422-20240428.md) |
| [![Star](https://img.shields.io/github/stars/huggingface/autotrain-advanced.svg?style=social&label=Star)](https://github.com/huggingface/autotrain-advanced)<br> [无代训练解决方案](https://github.com/huggingface/autotrain-advanced) |​​AutoTrain Advanced：更快、更轻松地训练和部署最先进的机器学习模型。 AutoTrain Advanced 是一种无代码解决方案，只需单击几下即可训练机器学习模型。  |LLM |[Awesome Project第27期](contents/20240422-20240428/20240422-20240428.md) |
| [![Star](https://img.shields.io/github/stars/UnicomAI/Unichat-llama3-Chinese.svg?style=social&label=Star)](https://github.com/UnicomAI/Unichat-llama3-Chinese)<br> [业界第一个llama3中文指令微调模型](https://github.com/UnicomAI/Unichat-llama3-Chinese) |​​中国联通AI创新中心发布业界第一个llama3中文指令微调模型长文本版本，支持28K上下文输入，本模型以Meta Llama 3为基础,增加中文数据进行训练,实现llama3模型高质量中文问答，使用高质量指令数据，覆盖多个领域和行业，为模型训练提供充足的数据支持。  |LLM |[Awesome Project第27期](contents/20240422-20240428/20240422-20240428.md) |
| [![Star](https://img.shields.io/github/stars/AviSoori1x/seemore.svg?style=social&label=Star)](https://github.com/AviSoori1x/seemore)<br> [在 PyTorch 中从头开始实现视觉语言模型](https://github.com/AviSoori1x/seemore) |​​ 在pytorch 中实现了一个由图像编码器、多模态投影模块和解码器语言模型组成的视觉语言模型。 “seemore”这个名字是向 Andrej Karpathy 的项目“makemore”致敬的方式，因为在这里使用了字符级自回归语言模型，就像他的 nanoGPT/makemore 实现一样。目标是在阅读此博客并逐步执行存储库中的代码后，能够直观地了解这一切是如何工作的。  |LLM |[Awesome Project第27期](contents/20240422-20240428/20240422-20240428.md) |
| [![Star](https://img.shields.io/github/stars/IR-LLM/Awesome-Information-Retrieval-in-the-Age-of-Large-Language-Model.svg?style=social&label=Star)](https://github.com/IR-LLM/Awesome-Information-Retrieval-in-the-Age-of-Large-Language-Model)<br> [Awesome Information Retrieval in the Age of Large Language Model](https://github.com/IR-LLM/Awesome-Information-Retrieval-in-the-Age-of-Large-Language-Model) |​​关于大语言模型时代信息检索 (IR) 的精彩论文精选列表。其中包括检索增强大语言模型、用于信息检索的大语言模型等等  |LLM |[Awesome Project第28期](contents/20240429-20240505/20240429-20240505.md) |
| [![Star](https://img.shields.io/github/stars/dnhkng/GlaDOS.svg?style=social&label=Star)](https://github.com/dnhkng/GlaDOS)<br> [传送门GLaDOS](https://github.com/dnhkng/GlaDOS) |​​这是一个致力于构建现实版 GLaDOS 的项目。将创建一个有意识的、交互式的、具体化的 GLaDOS。最初的目标是开发一个低延迟平台，GLaDOS 可以在 600 毫秒内响应语音交互。为此，系统不断地将数据记录到循环缓冲区中，等待检测到语音。当确定语音已停止（包括检测到正常停顿）时，将快速转录。然后将其传递到流式本地大型语言模型，其中流式文本按句子分解，并传递到文本转语音系统。这意味着在播放当前内容时可以生成更多句子，从而大大减少延迟。该项目的另一个目标是最大限度地减少依赖性，因此可以在受限的硬件上运行。这意味着没有 PyTorch 或其他大型软件包。  |LLM |[Awesome Project第28期](contents/20240429-20240505/20240429-20240505.md) |
| [![Star](https://img.shields.io/github/stars/ItzCrazyKns/Perplexica.svg?style=social&label=Star)](https://github.com/ItzCrazyKns/Perplexica)<br> [Perplexity AI平替](https://github.com/ItzCrazyKns/Perplexica) |​​Perplexica 是一款开源的人工智能搜索工具或人工智能搜索引擎，可以深入互联网寻找答案。受到 Perplexity AI 的启发，它是一个开源选项，不仅可以搜索网络，还可以理解您的问题。它使用相似性搜索和嵌入等先进的机器学习算法来完善结果，并提供明确的答案和引用的来源。  |LLM |[Awesome Project第28期](contents/20240429-20240505/20240429-20240505.md) |
| [![Star](https://img.shields.io/github/stars/Ruixxxx/Awesome-Vision-Mamba-Models.svg?style=social&label=Star)](https://github.com/Ruixxxx/Awesome-Vision-Mamba-Models)<br> [Awesome-Vision-Mamba-Models](https://github.com/Ruixxxx/Awesome-Vision-Mamba-Models) |​​Mamba 是一种新颖的状态空间模型，因其卓越的性能和高效的计算复杂性而获得了不同领域的认可。通过解决传统视觉基础模型固有的局限性，Mamba 成为一个有前途的竞争者，有望促进计算机视觉领域的进步。该存储库托管与计算机视觉中的 Mamba 模型相关的精选文献集。  |LLM |[Awesome Project第28期](contents/20240429-20240505/20240429-20240505.md) |
| [![Star](https://img.shields.io/github/stars/gptlint/gptlint.svg?style=social&label=Star)](https://github.com/gptlint/gptlint)<br> [GPTLint](https://github.com/gptlint/gptlint) |​​一种全新的代码质量方法。使用 LLMs 在整个代码库中实施更高级别的最佳实践，从而将 eslint 等传统静态分析工具提升到一个新的水平。  |LLM |[Awesome Project第28期](contents/20240429-20240505/20240429-20240505.md) |
| [![Star](https://img.shields.io/github/stars/ymcui/Chinese-LLaMA-Alpaca-3.svg?style=social&label=Star)](https://github.com/ymcui/Chinese-LLaMA-Alpaca-3)<br> [Chinese-LLaMA-Alpaca开源大模型第三期](https://github.com/ymcui/Chinese-LLaMA-Alpaca-3) |​​本项目基于Meta最新发布的新一代开源大模型Llama-3开发，是Chinese-LLaMA-Alpaca开源大模型相关系列项目（一期、二期）的第三期。本项目开源了中文Llama-3基座模型和中文Llama-3-Instruct指令精调大模型。这些模型在原版Llama-3的基础上使用了大规模中文数据进行增量预训练，并且使用精选指令数据进行精调，进一步提升了中文基础语义和指令理解能力，相比二代相关模型获得了显著性能提升。  |LLM |[Awesome Project第28期](contents/20240429-20240505/20240429-20240505.md) |
| [![Star](https://img.shields.io/github/stars/mlabonne/llm-datasets.svg?style=social&label=Star)](https://github.com/mlabonne/llm-datasets)<br> [用于LLM微调的高质量数据集、工具和概念](https://github.com/mlabonne/llm-datasets) |该​仓库是一个专注于大型语言模型（LLM）微调的资源库，提供了一系列高质量的数据集、工具和指南。它强调了高质量数据集的三个关键特性：准确性、多样性和复杂性，并包含了针对不同领域的专门数据集，如通用目的、数学逻辑、编程代码、对话角色扮演以及代理和函数调用。此外，仓库还提供了一系列工具来帮助数据去重、保证数据质量、探索数据和生成数据，旨在帮助开发者和研究人员提升LLM的性能和准确性。  |LLM |[Awesome Project第28期](contents/20240429-20240505/20240429-20240505.md) |
| [Kimi智能体](https://kimi.moonshot.cn/kimiplus-square) |​​Kimi推出的智能体，包含办公提效、辅助写作、社交娱乐、生活实用等多个方面的智能体。  |LLM |[Awesome Project第28期](contents/20240429-20240505/20240429-20240505.md) |
| [![Star](https://img.shields.io/github/stars/freeCodeCamp/freeCodeCamp.svg?style=social&label=Star)](https://github.com/freeCodeCamp/freeCodeCamp)<br> [freeCodeCamp](https://github.com/freeCodeCamp/freeCodeCamp) |​​freeCodeCamp.org 是一个友好的社区，您可以在其中免费学习编码。它由捐助者支持的 501(c)(3) 慈善机构运营，旨在帮助数百万忙碌的成年人过渡到科技行业。我们的社区已经帮助超过 40,000 人获得了第一份开发人员工作。全栈网络开发和机器学习课程完全免费且可自定进度。我们有数千个交互式编码挑战来帮助您扩展技能。  |AI教程 |[Awesome Project第28期](contents/20240429-20240505/20240429-20240505.md) |
| [![Star](https://img.shields.io/github/stars/OpenBMB/MiniCPM-V.svg?style=social&label=Star)](https://github.com/OpenBMB/MiniCPM-V)<br> [端侧可用的 GPT-4V 级多模态大模型](https://github.com/OpenBMB/MiniCPM-V) |​​MiniCPM-V是面向图文理解的端侧多模态大模型系列。该系列模型接受图像和文本输入，并提供高质量的文本输出。自2024年2月以来，我们共发布了4个版本模型，旨在实现领先的性能和高效的部署，目前该系列最值得关注的模型包括：  |LLM |[Awesome Project第29期](contents/20240506-20240512/20240506-20240512.md) |
| [![Star](https://img.shields.io/github/stars/Codium-ai/cover-agent.svg?style=social&label=Star)](https://github.com/Codium-ai/cover-agent)<br> [CodiumAI Cover Agent](https://github.com/Codium-ai/cover-agent) |​​Codium-ai/cover-agent是一个专注于自动化测试生成和代码覆盖率提升的AI驱动工具。它利用生成式AI简化和加速测试过程，确保软件开发质量。该工具包含多个组件，如测试运行器、覆盖率解析器、提示构建器和AI调用器，支持通过命令行运行，并计划集成到流行的CI平台。CodiumAI旨在帮助开发团队提高和维护代码完整性，提供开源工具的"Pro"版本，以应对企业级代码复杂性，并支持多代码库。  |LLM |[Awesome Project第29期](contents/20240506-20240512/20240506-20240512.md) |
| [![Star](https://img.shields.io/github/stars/ragapp/ragapp.svg?style=social&label=Star)](https://github.com/ragapp/ragapp)<br> [RAGapp](https://github.com/ragapp/ragapp) |​​ragapp项目提供了一种简单的方式来在企业中使用Agentic RAG（Retrieval-Augmented Generation）。它像OpenAI的定制GPT一样易于配置，但可以通过Docker部署在自己的云基础设施中，并使用LlamaIndex构建。项目提供了Docker容器运行指令、Admin UI和Chat UI的访问方式，以及API文档。它还提供了使用Docker Compose和Kubernetes的部署指南，并支持使用不同的环境变量来指定使用的模型和Ollama主机。  |LLM |[Awesome Project第29期](contents/20240506-20240512/20240506-20240512.md) |
| [![Star](https://img.shields.io/github/stars/ToolJet/ToolJet.svg?style=social&label=Star)](https://github.com/ToolJet/ToolJet)<br> [ToolJet](https://github.com/ToolJet/ToolJet) |ToolJet是一个开源的低代码应用构建平台，它允许用户快速构建和部署自定义的Web应用程序。ToolJet提供了一个拖放界面，用户可以通过它连接数据库、APIs和其他数据源，然后创建动态的仪表板和工作流程。它支持实时数据更新、用户身份验证和细粒度权限控制，非常适合需要快速开发内部工具或自动化工作流程的团队。ToolJet的目标是简化开发过程，帮助开发者和非技术用户以更高效的方式构建应用程序。  |LLM |[Awesome Project第29期](contents/20240506-20240512/20240506-20240512.md) |
| [![Star](https://img.shields.io/github/stars/talkdai/dialog.svg?style=social&label=Star)](https://github.com/talkdai/dialog)<br> [Dialog](https://github.com/talkdai/dialog) |​​对于对 AI 感兴趣的程序员来说，他们在不了解服务器维护的情况下部署 RAG，Dialog 是一款简化LLM部署的应用程序，让您花更少的时间编码，将更多的时间用于训练模型。此存储库提供一个 API，专注于让您根据 dialog-lib 提供的结构部署所需的任何LLM内容。  |LLM |[Awesome Project第29期](contents/20240506-20240512/20240506-20240512.md) |
| [![Star](https://img.shields.io/github/stars/mlabonne/llm-course.svg?style=social&label=Star)](https://github.com/mlabonne/llm-course)<br> [LLM课程（Large Language Model Course）](https://github.com/mlabonne/llm-course) |该GitHub仓库是一个关于机器学习课程的项目，由mlabonne维护。它似乎包含了一个用于教学目的的课程结构，覆盖了从基础到高级的机器学习概念，包含教程、笔记、代码示例以及可能的作业和解决方案，旨在帮助学生和自学者掌握机器学习领域的知识与技能。  |AI Course |[Awesome Project第29期](contents/20240506-20240512/20240506-20240512.md) |
| [![Star](https://img.shields.io/github/stars/sugarforever/wtf-langchain.svg?style=social&label=Star)](https://github.com/sugarforever/wtf-langchain)<br> [wtf-langchain](https://github.com/sugarforever/wtf-langchain) |Langchain框架的开源教程，提供从入门到实践的详细指南，帮助用户快速掌握Langchain的使用和开发.  |AI Course |[Awesome Project第29期](contents/20240506-20240512/20240506-20240512.md) |
| [一起学多 AI 智能体系统](https://learn.deeplearning.ai/courses/multi-ai-agent-systems-with-crewai/lesson/1/introduction) |​​智能体是一种可以进行自我对话并完成复杂任务的大语言模型。通过协同工作，智能体能够实现更高的价值。在实际操作中，我们通过导入 crewAI 的 Agent、Task 和 Crew 三个核心模块，选择适当的语言模型，如 GPT-3.5 Turbo，来搭建多智能体系统。  |AI Course |[Awesome Project第29期](contents/20240506-20240512/20240506-20240512.md) |
| [![Star](https://img.shields.io/github/stars/lllyasviel/Omost.svg?style=social&label=Star)](https://github.com/lllyasviel/Omost)<br> [Omost](https://github.com/lllyasviel/Omost) |​​Omost是一个将编码能力转换为LLM图像生成能力的项目。Omost提供了LLMs一些模型，这些模型将编写代码，以使用Omost的虚拟 Canvas 代理来组合图像视觉内容。这 Canvas 可以通过图像生成器的特定实现来呈现，以实际生成图像。所有模型都使用混合数据进行训练：（1） 包括 Open-Images 在内的多个数据集的地面实况注释，（2） 通过自动注释图像提取数据，（3） 来自 DPO（直接偏好优化，“代码是否可以由 python 3.10 编译”作为直接偏好）的强化，以及 （4） 来自 OpenAI GPT4o 多模态功能的少量调整数据。  |LLM |[Awesome Project第30期](contents/20240513-20240519/20240513-20240519.md) |
| [![Star](https://img.shields.io/github/stars/2noise/ChatTTS。.svg?style=social&label=Star)](https://github.com/2noise/ChatTTS。)<br> [ChatTTS](https://github.com/2noise/ChatTTS。) |​ChatTTS是专门为对话场景设计的文本转语音模型，例如LLM助手对话任务。它支持英文和中文两种语言。最大的模型使用了10万小时以上的中英文数据进行训练。在HuggingFace中开源的版本为4万小时训练且未SFT的版本.  |LLM |[Awesome Project第30期](contents/20240513-20240519/20240513-20240519.md) |
| [![Star](https://img.shields.io/github/stars/jianchang512/ChatTTS-ui.svg?style=social&label=Star)](https://github.com/jianchang512/ChatTTS-ui)<br> [ChatTTS webUI & API](https://github.com/jianchang512/ChatTTS-ui) |​​一个简单的本地网页界面，直接在网页使用 ChatTTS 将文字合成为语音，同时支持对外提供API接口。  |LLM |[Awesome Project第30期](contents/20240513-20240519/20240513-20240519.md) |
| [![Star](https://img.shields.io/github/stars/enoch3712/ExtractThinker.svg?style=social&label=Star)](https://github.com/enoch3712/ExtractThinker)<br> [ExtractThinker](https://github.com/enoch3712/ExtractThinker) |​​ExtractThinker 是一款基于大型语言模型 (LLM) 的人工智能文档智能工具，它可以帮助您从各种文档中提取关键信息。它可以用于各种任务，例如：从文本中提取事实和数据、总结文章的主要内容、生成摘要、翻译语言、创建问答系统。  |LLM |[Awesome Project第30期](contents/20240513-20240519/20240513-20240519.md) |
| [![Star](https://img.shields.io/github/stars/VikParuchuri/surya.svg?style=social&label=Star)](https://github.com/VikParuchuri/surya)<br> [surya](https://github.com/VikParuchuri/surya) |​一款​OCR、布局分析、阅读顺序、90+ 种语言的行检测工具。  |LLM |[Awesome Project第30期](contents/20240513-20240519/20240513-20240519.md) |
| [![Star](https://img.shields.io/github/stars/Marker-Inc-Korea/AutoRAG.svg?style=social&label=Star)](https://github.com/Marker-Inc-Korea/AutoRAG)<br> [AutoRAG](https://github.com/Marker-Inc-Korea/AutoRAG) |​​AutoRAG 是一种用于为“您的数据”寻找最佳 RAG 管道的工具。您可以使用自己的评估数据自动评估各种 RAG 模块，并找到适合您自己的用例的最佳 RAG 管道。AutoRAG 支持一种简单的方法来评估许多 RAG 模块组合。立即尝试并找到适合您自己的用例的最佳 RAG 管道。  |LLM |[Awesome Project第30期](contents/20240513-20240519/20240513-20240519.md) |
| [![Star](https://img.shields.io/github/stars/AstraBert/everything-ai.svg?style=social&label=Star)](https://github.com/AstraBert/everything-ai)<br> [everything-ai](https://github.com/AstraBert/everything-ai) |​一款人工智能本地聊天机器人助手，支持各种任务，包括利用qdrant后端构建检索友好的知识库、类似ChatGPT的文本生成、文本摘要、图像生成、图像分类、图像到文本的描述、音频分类、语音识别、视频生成、蛋白质折叠结构预测、自动微调模型、使用HF Spaces API与Supabase数据库结合、以及使用lamma.cpp和qdrant进行检索文本生成等。这些任务支持多种语言，部分任务需要特定的硬件支持，如GPU。  |LLM |[Awesome Project第30期](contents/20240513-20240519/20240513-20240519.md) |
| [![Star](https://img.shields.io/github/stars/tangjyan/zh-cn.svg?style=social&label=Star)](https://github.com/tangjyan/zh-cn)<br> [中文学术主页](https://github.com/tangjyan/zh-cn) |​​这个项目仓库提供了一个自动更新且优化设计的个人学术主页解决方案。它利用谷歌学术爬虫和GitHub Actions实现引用数的自动更新，支持谷歌Analytics进行流量追踪，具备响应式设计以适配多种设备屏幕，展现美观简约的界面风格，并融入搜索引擎优化策略，有助于提升在线可见性和排名，非常适合学者构建专业在线形象。  |其他工具 |[Awesome Project第30期](contents/20240513-20240519/20240513-20240519.md) |
