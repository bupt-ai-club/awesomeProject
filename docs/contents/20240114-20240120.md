# Awesome Project第13期

## LLM

### ChatLM-mini-Chinese（0.2B）

- 链接： https://github.com/charent/ChatLM-mini-Chinese
  
- 介绍：​​​ 中文对话0.2B小模型（ChatLM-Chinese-0.2B），开源所有数据集来源、数据清洗、tokenizer训练、模型预训练、SFT指令微调、RLHF优化等流程的全部代码。支持下游任务sft微调。ChatLM-mini-Chinese为中文对话小模型，模型参数只有0.2B（算共享权重约210M），可以在最低4GB显存的机器进行预训练（batch_size=1，fp16或者 bf16），float16加载、推理最少只需要512MB显存。

- 推荐指数：⭐️⭐️⭐️⭐️⭐️


### AI 研发提效研究：自己动手训练 LoRA

- 链接： https://github.com/unit-mesh/unit-minions
  
- 介绍：​​​ 《AI 研发提效研究：自己动手训练 LoRA》，包含 Llama （Alpaca LoRA）模型、ChatGLM （ChatGLM Tuning）相关 Lora 的训练。训练内容：用户故事生成、测试代码生成、代码辅助生成、文本转 SQL、文本生成代码。包括了一些视频介绍、训练好的模型、训练代码、训练数据、训练过程中的一些记录。

- 推荐指数：⭐️⭐️⭐️⭐️⭐️


### KG_RAG

- 链接： https://github.com/BaranziniLab/KG_RAG
  
- 介绍：​​​ 使用基于知识图的检索增强生成 (KG-RAG) 为知识密集型任务赋能大型语言模型 (LLM)框架。该框架通过合并来自生物医学知识库的优化的特定领域“提示感知上下文”，支持通用LLM。

- 推荐指数：⭐️⭐️⭐️⭐️⭐️


### 高效人工智能推理和服务SwiftInfer

- 链接： https://github.com/hpcaitech/SwiftInfer
  
- 介绍：​​Streaming-LLM 是一种支持无限输入长度进行 LLM 推理的技术。它利用注意力池来防止注意力窗口转移时模型崩溃。最初的工作是在 PyTorch 中实现的，我们提供 SwiftInfer，一个 TensorRT 实现，使 StreamingLLM 更具生产级。我们的实现基于最近发布的 TensorRT-LLM 项目。

- 推荐指数：⭐️⭐️⭐️⭐️⭐️

